{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepLearning Assignment 4 实验报告\n",
    "# SA22221042 汪泱泱"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、实验环境"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU TITAN Xp  \n",
    "CUDA 10.1  \n",
    "python 3.7.13  \n",
    "torch 1.8.1  \n",
    "torchtext 0.6.0  \n",
    "spacy 3.4.3  \n",
    "transformers-4.25.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、实验过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.datasets import PPI\n",
    "from torch_geometric.nn import GCNConv\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(dataset_name):\n",
    "    assert(dataset_name in ['cora', 'citeseer'])\n",
    "    cites_path = os.path.join('./dataset', dataset_name, dataset_name+'.cites')\n",
    "    content_path = os.path.join('./dataset', dataset_name, dataset_name+'.content')\n",
    "    labels = []\n",
    "    features = []\n",
    "    ids = []\n",
    "    edges = []\n",
    "    paper_reindex = dict()\n",
    "    label_reindex = dict()\n",
    "                \n",
    "    with open(content_path ,\"r\") as f:\n",
    "        node_lines = f.readlines()\n",
    "        index_cnt = 0\n",
    "        label_cnt = 0\n",
    "        for line in node_lines:\n",
    "            node = line.strip('\\n').split('\\t')\n",
    "            if node[0] not in paper_reindex:\n",
    "                paper_reindex[node[0]] = index_cnt\n",
    "                index_cnt += 1\n",
    "            if node[-1] not in label_reindex:\n",
    "                label_reindex[node[-1]] = label_cnt\n",
    "                label_cnt += 1\n",
    "        for line in node_lines:\n",
    "            node = line.strip('\\n').split('\\t')\n",
    "            ids.append(paper_reindex[node[0]])\n",
    "            features.append(node[1: -1])\n",
    "            labels.append(node[-1])\n",
    "        x = np.zeros(shape=(index_cnt, len(features[0])), dtype=int)\n",
    "        y = np.zeros(shape=(index_cnt, 1), dtype=int)\n",
    "        for i in range(len(ids)):\n",
    "            for j in range(len(features[i])):\n",
    "                x[i][j] = int(features[i][j])\n",
    "            y[i][0] = label_reindex[labels[i]]\n",
    "            \n",
    "    with open(cites_path,\"r\") as f:\n",
    "        edge_lines = f.readlines()\n",
    "        edge_index = np.zeros(shape=(2, len(edge_lines)*2), dtype=int)\n",
    "        edge_num = 0\n",
    "        for line in edge_lines:\n",
    "            edge = line.strip('\\n').split('\\t')\n",
    "            if edge[0] not in paper_reindex or edge[1] not in paper_reindex:\n",
    "                continue\n",
    "            edge_index[0][edge_num] = paper_reindex[edge[0]]\n",
    "            edge_index[1][edge_num] = paper_reindex[edge[1]]\n",
    "            edge_num += 1\n",
    "            edge_index[0][edge_num] = paper_reindex[edge[1]]\n",
    "            edge_index[1][edge_num] = paper_reindex[edge[0]]\n",
    "            edge_num += 1\n",
    "        edge_index = edge_index[:, :edge_num]\n",
    "    return x, edge_index, y, len(paper_reindex), len(label_reindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37025/3127728522.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaper_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'citeseer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_37025/3439700946.py\u001b[0m in \u001b[0;36mread_data\u001b[0;34m(dataset_name)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_reindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x, edge_index, y, paper_num, label_num = read_data('citeseer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.FloatTensor(x).to(device)\n",
    "x = F.normalize(x, p=1, dim=1)\n",
    "edge_index=torch.LongTensor(edge_index).to(device)\n",
    "y=torch.LongTensor(y).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(x=x, edge_index=edge_index, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3312, 3703])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_num = len(y) \n",
    "train_num = 300\n",
    "val_num = 500\n",
    "test_num = samples_num - train_num - val_num\n",
    "ids = np.random.permutation(samples_num)\n",
    "train_id = torch.LongTensor(ids[:train_num]).to(device)\n",
    "val_id = torch.LongTensor(ids[train_num:train_num+val_num]).to(device)\n",
    "test_id = torch.LongTensor(ids[train_num+train_num:]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0,    0,    0,  ...,  455, 2175, 2122],\n",
      "        [   0,    0,   99,  ..., 1008, 2122, 2175]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, hidden_layer_num, input_size, output_size, layer_size, dropout_rate, activation):\n",
    "        super().__init__()\n",
    "        assert hidden_layer_num>0\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.gcn_list = nn.ModuleList()\n",
    "        self.gcn_list.append(GCNConv(input_size, layer_size))\n",
    "        self.activation = activation\n",
    "        for i in range(hidden_layer_num-1):\n",
    "            self.gcn_list.append(GCNConv(layer_size, layer_size))\n",
    "        self.gcn_list.append(GCNConv(layer_size, output_size))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for i in range(len(self.gcn_list)):\n",
    "            x = self.gcn_list[i](x, edge_index)\n",
    "            if i != len(self.gcn_list)-1:\n",
    "                if self.activation == 'relu':\n",
    "                    x = F.relu(x)\n",
    "                elif self.activation == 'tanh':\n",
    "                    x = F.tanh(x)\n",
    "                else:\n",
    "                    x = F.sigmoid(x)\n",
    "                x = F.dropout(x, self.dropout_rate)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_num = 1\n",
    "input_size = x.shape[1]\n",
    "output_size = label_num\n",
    "layer_size = 32\n",
    "dropout_rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(hidden_layer_num, input_size, output_size, layer_size, dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_acc(y_pred, y_true):\n",
    "    return (y_pred.argmax(1) == y_true).type(torch.float32).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10/2000] train_loss = 1.76283, train_acc = 0.44000, val_acc = 0.27600\n",
      "[Epoch 20/2000] train_loss = 1.72186, train_acc = 0.46667, val_acc = 0.28600\n",
      "[Epoch 30/2000] train_loss = 1.68229, train_acc = 0.46667, val_acc = 0.27600\n",
      "[Epoch 40/2000] train_loss = 1.64005, train_acc = 0.47667, val_acc = 0.29000\n",
      "[Epoch 50/2000] train_loss = 1.60367, train_acc = 0.53667, val_acc = 0.28400\n",
      "[Epoch 60/2000] train_loss = 1.56527, train_acc = 0.57333, val_acc = 0.31000\n",
      "[Epoch 70/2000] train_loss = 1.52310, train_acc = 0.62333, val_acc = 0.35600\n",
      "[Epoch 80/2000] train_loss = 1.47716, train_acc = 0.66667, val_acc = 0.38200\n",
      "[Epoch 90/2000] train_loss = 1.44128, train_acc = 0.65667, val_acc = 0.43400\n",
      "[Epoch 100/2000] train_loss = 1.38129, train_acc = 0.71667, val_acc = 0.43000\n",
      "[Epoch 110/2000] train_loss = 1.32964, train_acc = 0.72333, val_acc = 0.48400\n",
      "[Epoch 120/2000] train_loss = 1.27705, train_acc = 0.78333, val_acc = 0.48000\n",
      "[Epoch 130/2000] train_loss = 1.22878, train_acc = 0.78667, val_acc = 0.55200\n",
      "[Epoch 140/2000] train_loss = 1.18544, train_acc = 0.80333, val_acc = 0.52800\n",
      "[Epoch 150/2000] train_loss = 1.13919, train_acc = 0.81333, val_acc = 0.56000\n",
      "[Epoch 160/2000] train_loss = 1.12378, train_acc = 0.82333, val_acc = 0.56000\n",
      "[Epoch 170/2000] train_loss = 1.07677, train_acc = 0.82000, val_acc = 0.58200\n",
      "[Epoch 180/2000] train_loss = 1.03370, train_acc = 0.82667, val_acc = 0.62000\n",
      "[Epoch 190/2000] train_loss = 1.03649, train_acc = 0.82333, val_acc = 0.59600\n",
      "[Epoch 200/2000] train_loss = 0.95181, train_acc = 0.87000, val_acc = 0.61400\n",
      "[Epoch 210/2000] train_loss = 0.93682, train_acc = 0.84667, val_acc = 0.63600\n",
      "[Epoch 220/2000] train_loss = 0.92470, train_acc = 0.85333, val_acc = 0.65000\n",
      "[Epoch 230/2000] train_loss = 0.88623, train_acc = 0.86667, val_acc = 0.61600\n",
      "[Epoch 240/2000] train_loss = 0.87423, train_acc = 0.85667, val_acc = 0.65200\n",
      "[Epoch 250/2000] train_loss = 0.84112, train_acc = 0.85667, val_acc = 0.64000\n",
      "[Epoch 260/2000] train_loss = 0.81063, train_acc = 0.86667, val_acc = 0.65600\n",
      "[Epoch 270/2000] train_loss = 0.77823, train_acc = 0.87000, val_acc = 0.64800\n",
      "[Epoch 280/2000] train_loss = 0.77583, train_acc = 0.86000, val_acc = 0.64000\n",
      "[Epoch 290/2000] train_loss = 0.76729, train_acc = 0.87000, val_acc = 0.65600\n",
      "[Epoch 300/2000] train_loss = 0.74346, train_acc = 0.86333, val_acc = 0.65600\n",
      "[Epoch 310/2000] train_loss = 0.73417, train_acc = 0.88000, val_acc = 0.65000\n",
      "[Epoch 320/2000] train_loss = 0.72168, train_acc = 0.87000, val_acc = 0.66800\n",
      "[Epoch 330/2000] train_loss = 0.68934, train_acc = 0.90333, val_acc = 0.67000\n",
      "[Epoch 340/2000] train_loss = 0.66994, train_acc = 0.88667, val_acc = 0.66000\n",
      "[Epoch 350/2000] train_loss = 0.66482, train_acc = 0.88667, val_acc = 0.65400\n",
      "[Epoch 360/2000] train_loss = 0.66182, train_acc = 0.91667, val_acc = 0.67000\n",
      "[Epoch 370/2000] train_loss = 0.65450, train_acc = 0.88667, val_acc = 0.67800\n",
      "[Epoch 380/2000] train_loss = 0.62074, train_acc = 0.89333, val_acc = 0.67600\n",
      "[Epoch 390/2000] train_loss = 0.60877, train_acc = 0.89000, val_acc = 0.65400\n",
      "[Epoch 400/2000] train_loss = 0.63280, train_acc = 0.91000, val_acc = 0.67400\n",
      "[Epoch 410/2000] train_loss = 0.61998, train_acc = 0.90667, val_acc = 0.68200\n",
      "[Epoch 420/2000] train_loss = 0.60854, train_acc = 0.89000, val_acc = 0.65200\n",
      "[Epoch 430/2000] train_loss = 0.58221, train_acc = 0.92333, val_acc = 0.66800\n",
      "[Epoch 440/2000] train_loss = 0.58301, train_acc = 0.91333, val_acc = 0.69000\n",
      "[Epoch 450/2000] train_loss = 0.58550, train_acc = 0.90333, val_acc = 0.68800\n",
      "[Epoch 460/2000] train_loss = 0.54855, train_acc = 0.90333, val_acc = 0.67600\n",
      "[Epoch 470/2000] train_loss = 0.54595, train_acc = 0.90333, val_acc = 0.66000\n",
      "[Epoch 480/2000] train_loss = 0.55102, train_acc = 0.91667, val_acc = 0.67600\n",
      "[Epoch 490/2000] train_loss = 0.55253, train_acc = 0.90667, val_acc = 0.67200\n",
      "[Epoch 500/2000] train_loss = 0.52590, train_acc = 0.89667, val_acc = 0.68200\n",
      "[Epoch 510/2000] train_loss = 0.52824, train_acc = 0.91667, val_acc = 0.66200\n",
      "[Epoch 520/2000] train_loss = 0.51644, train_acc = 0.92667, val_acc = 0.68400\n",
      "[Epoch 530/2000] train_loss = 0.52283, train_acc = 0.93667, val_acc = 0.68200\n",
      "[Epoch 540/2000] train_loss = 0.52571, train_acc = 0.91000, val_acc = 0.67200\n",
      "[Epoch 550/2000] train_loss = 0.51671, train_acc = 0.93333, val_acc = 0.70800\n",
      "[Epoch 560/2000] train_loss = 0.49715, train_acc = 0.92333, val_acc = 0.68200\n",
      "[Epoch 570/2000] train_loss = 0.47935, train_acc = 0.94000, val_acc = 0.65400\n",
      "[Epoch 580/2000] train_loss = 0.48892, train_acc = 0.92333, val_acc = 0.68000\n",
      "[Epoch 590/2000] train_loss = 0.47611, train_acc = 0.93000, val_acc = 0.68600\n",
      "[Epoch 600/2000] train_loss = 0.48819, train_acc = 0.92333, val_acc = 0.68600\n",
      "[Epoch 610/2000] train_loss = 0.44898, train_acc = 0.94333, val_acc = 0.67200\n",
      "[Epoch 620/2000] train_loss = 0.47370, train_acc = 0.93333, val_acc = 0.67200\n",
      "[Epoch 630/2000] train_loss = 0.46364, train_acc = 0.93333, val_acc = 0.69000\n",
      "[Epoch 640/2000] train_loss = 0.44862, train_acc = 0.93333, val_acc = 0.66600\n",
      "[Epoch 650/2000] train_loss = 0.46346, train_acc = 0.90667, val_acc = 0.68800\n",
      "[Epoch 660/2000] train_loss = 0.43772, train_acc = 0.94000, val_acc = 0.67600\n",
      "[Epoch 670/2000] train_loss = 0.45344, train_acc = 0.93333, val_acc = 0.70200\n",
      "[Epoch 680/2000] train_loss = 0.44850, train_acc = 0.93333, val_acc = 0.69800\n",
      "[Epoch 690/2000] train_loss = 0.42883, train_acc = 0.93667, val_acc = 0.67600\n",
      "[Epoch 700/2000] train_loss = 0.41853, train_acc = 0.95667, val_acc = 0.68200\n",
      "[Epoch 710/2000] train_loss = 0.42949, train_acc = 0.94667, val_acc = 0.67800\n",
      "[Epoch 720/2000] train_loss = 0.43829, train_acc = 0.93000, val_acc = 0.70200\n",
      "[Epoch 730/2000] train_loss = 0.41066, train_acc = 0.94333, val_acc = 0.69800\n",
      "[Epoch 740/2000] train_loss = 0.41204, train_acc = 0.95333, val_acc = 0.70000\n",
      "[Epoch 750/2000] train_loss = 0.43879, train_acc = 0.94000, val_acc = 0.69600\n",
      "[Epoch 760/2000] train_loss = 0.41251, train_acc = 0.93667, val_acc = 0.68600\n",
      "[Epoch 770/2000] train_loss = 0.41565, train_acc = 0.95000, val_acc = 0.69000\n",
      "[Epoch 780/2000] train_loss = 0.39374, train_acc = 0.94333, val_acc = 0.68200\n",
      "[Epoch 790/2000] train_loss = 0.40784, train_acc = 0.94667, val_acc = 0.69000\n",
      "[Epoch 800/2000] train_loss = 0.38951, train_acc = 0.95000, val_acc = 0.69600\n",
      "[Epoch 810/2000] train_loss = 0.39576, train_acc = 0.94333, val_acc = 0.69600\n",
      "[Epoch 820/2000] train_loss = 0.39096, train_acc = 0.96000, val_acc = 0.69400\n",
      "[Epoch 830/2000] train_loss = 0.37962, train_acc = 0.95000, val_acc = 0.69000\n",
      "[Epoch 840/2000] train_loss = 0.38249, train_acc = 0.95333, val_acc = 0.69000\n",
      "[Epoch 850/2000] train_loss = 0.40232, train_acc = 0.95333, val_acc = 0.69600\n",
      "[Epoch 860/2000] train_loss = 0.37803, train_acc = 0.96000, val_acc = 0.67800\n",
      "[Epoch 870/2000] train_loss = 0.37744, train_acc = 0.94333, val_acc = 0.67400\n",
      "[Epoch 880/2000] train_loss = 0.37485, train_acc = 0.95667, val_acc = 0.68200\n",
      "[Epoch 890/2000] train_loss = 0.38380, train_acc = 0.94667, val_acc = 0.70000\n",
      "[Epoch 900/2000] train_loss = 0.36371, train_acc = 0.96000, val_acc = 0.68600\n",
      "[Epoch 910/2000] train_loss = 0.37265, train_acc = 0.95000, val_acc = 0.69000\n",
      "[Epoch 920/2000] train_loss = 0.36631, train_acc = 0.96333, val_acc = 0.70000\n",
      "[Epoch 930/2000] train_loss = 0.37875, train_acc = 0.96000, val_acc = 0.68000\n",
      "[Epoch 940/2000] train_loss = 0.35819, train_acc = 0.96333, val_acc = 0.67200\n",
      "[Epoch 950/2000] train_loss = 0.36262, train_acc = 0.94667, val_acc = 0.69600\n",
      "[Epoch 960/2000] train_loss = 0.36595, train_acc = 0.93667, val_acc = 0.69200\n",
      "[Epoch 970/2000] train_loss = 0.36766, train_acc = 0.95333, val_acc = 0.69400\n",
      "[Epoch 980/2000] train_loss = 0.34955, train_acc = 0.96000, val_acc = 0.68800\n",
      "[Epoch 990/2000] train_loss = 0.35532, train_acc = 0.94333, val_acc = 0.68400\n",
      "[Epoch 1000/2000] train_loss = 0.35456, train_acc = 0.95333, val_acc = 0.69400\n",
      "[Epoch 1010/2000] train_loss = 0.35052, train_acc = 0.96000, val_acc = 0.67800\n",
      "[Epoch 1020/2000] train_loss = 0.33159, train_acc = 0.96333, val_acc = 0.69200\n",
      "[Epoch 1030/2000] train_loss = 0.34998, train_acc = 0.96667, val_acc = 0.71000\n",
      "[Epoch 1040/2000] train_loss = 0.33888, train_acc = 0.95333, val_acc = 0.69000\n",
      "[Epoch 1050/2000] train_loss = 0.33696, train_acc = 0.94667, val_acc = 0.69400\n",
      "[Epoch 1060/2000] train_loss = 0.33592, train_acc = 0.95333, val_acc = 0.68600\n",
      "[Epoch 1070/2000] train_loss = 0.34657, train_acc = 0.94333, val_acc = 0.69200\n",
      "[Epoch 1080/2000] train_loss = 0.33202, train_acc = 0.95000, val_acc = 0.69400\n",
      "[Epoch 1090/2000] train_loss = 0.33802, train_acc = 0.95333, val_acc = 0.69200\n",
      "[Epoch 1100/2000] train_loss = 0.34607, train_acc = 0.96000, val_acc = 0.69600\n",
      "[Epoch 1110/2000] train_loss = 0.32915, train_acc = 0.96333, val_acc = 0.70000\n",
      "[Epoch 1120/2000] train_loss = 0.33694, train_acc = 0.96667, val_acc = 0.70200\n",
      "[Epoch 1130/2000] train_loss = 0.34447, train_acc = 0.94667, val_acc = 0.69200\n",
      "[Epoch 1140/2000] train_loss = 0.32465, train_acc = 0.96333, val_acc = 0.70400\n",
      "[Epoch 1150/2000] train_loss = 0.32384, train_acc = 0.96667, val_acc = 0.69800\n",
      "[Epoch 1160/2000] train_loss = 0.32154, train_acc = 0.97000, val_acc = 0.69400\n",
      "[Epoch 1170/2000] train_loss = 0.31258, train_acc = 0.97333, val_acc = 0.69600\n",
      "[Epoch 1180/2000] train_loss = 0.34300, train_acc = 0.96000, val_acc = 0.67800\n",
      "[Epoch 1190/2000] train_loss = 0.30933, train_acc = 0.97000, val_acc = 0.70000\n",
      "[Epoch 1200/2000] train_loss = 0.32954, train_acc = 0.95667, val_acc = 0.68600\n",
      "[Epoch 1210/2000] train_loss = 0.33023, train_acc = 0.96333, val_acc = 0.70600\n",
      "[Epoch 1220/2000] train_loss = 0.33212, train_acc = 0.95000, val_acc = 0.68800\n",
      "[Epoch 1230/2000] train_loss = 0.31465, train_acc = 0.95333, val_acc = 0.68400\n",
      "[Epoch 1240/2000] train_loss = 0.30010, train_acc = 0.95333, val_acc = 0.70000\n",
      "[Epoch 1250/2000] train_loss = 0.30837, train_acc = 0.95667, val_acc = 0.66800\n",
      "[Epoch 1260/2000] train_loss = 0.30828, train_acc = 0.97333, val_acc = 0.69400\n",
      "[Epoch 1270/2000] train_loss = 0.32886, train_acc = 0.96333, val_acc = 0.69600\n",
      "[Epoch 1280/2000] train_loss = 0.30785, train_acc = 0.97000, val_acc = 0.67400\n",
      "[Epoch 1290/2000] train_loss = 0.30271, train_acc = 0.96000, val_acc = 0.70800\n",
      "[Epoch 1300/2000] train_loss = 0.30365, train_acc = 0.96333, val_acc = 0.69600\n",
      "[Epoch 1310/2000] train_loss = 0.30418, train_acc = 0.96000, val_acc = 0.70600\n",
      "[Epoch 1320/2000] train_loss = 0.31555, train_acc = 0.97333, val_acc = 0.68800\n",
      "[Epoch 1330/2000] train_loss = 0.32444, train_acc = 0.96000, val_acc = 0.67800\n",
      "[Epoch 1340/2000] train_loss = 0.29812, train_acc = 0.96667, val_acc = 0.70600\n",
      "[Epoch 1350/2000] train_loss = 0.30528, train_acc = 0.97000, val_acc = 0.68000\n",
      "[Epoch 1360/2000] train_loss = 0.29379, train_acc = 0.96333, val_acc = 0.68800\n",
      "[Epoch 1370/2000] train_loss = 0.28911, train_acc = 0.97000, val_acc = 0.68800\n",
      "[Epoch 1380/2000] train_loss = 0.28736, train_acc = 0.97667, val_acc = 0.69000\n",
      "[Epoch 1390/2000] train_loss = 0.30166, train_acc = 0.96000, val_acc = 0.69600\n",
      "[Epoch 1400/2000] train_loss = 0.29783, train_acc = 0.97000, val_acc = 0.68000\n",
      "[Epoch 1410/2000] train_loss = 0.29514, train_acc = 0.97000, val_acc = 0.72400\n",
      "[Epoch 1420/2000] train_loss = 0.30613, train_acc = 0.96667, val_acc = 0.70200\n",
      "[Epoch 1430/2000] train_loss = 0.28333, train_acc = 0.96000, val_acc = 0.71600\n",
      "[Epoch 1440/2000] train_loss = 0.28225, train_acc = 0.97667, val_acc = 0.69800\n",
      "[Epoch 1450/2000] train_loss = 0.30471, train_acc = 0.97000, val_acc = 0.68200\n",
      "[Epoch 1460/2000] train_loss = 0.30839, train_acc = 0.96333, val_acc = 0.68600\n",
      "[Epoch 1470/2000] train_loss = 0.28891, train_acc = 0.97333, val_acc = 0.68200\n",
      "[Epoch 1480/2000] train_loss = 0.28094, train_acc = 0.96667, val_acc = 0.70600\n",
      "[Epoch 1490/2000] train_loss = 0.29170, train_acc = 0.96667, val_acc = 0.68400\n",
      "[Epoch 1500/2000] train_loss = 0.27343, train_acc = 0.98667, val_acc = 0.68400\n",
      "[Epoch 1510/2000] train_loss = 0.28293, train_acc = 0.97667, val_acc = 0.70200\n",
      "[Epoch 1520/2000] train_loss = 0.27864, train_acc = 0.97000, val_acc = 0.70800\n",
      "[Epoch 1530/2000] train_loss = 0.27565, train_acc = 0.96667, val_acc = 0.69400\n",
      "[Epoch 1540/2000] train_loss = 0.29720, train_acc = 0.95667, val_acc = 0.69000\n",
      "[Epoch 1550/2000] train_loss = 0.30422, train_acc = 0.96000, val_acc = 0.70800\n",
      "[Epoch 1560/2000] train_loss = 0.27940, train_acc = 0.98333, val_acc = 0.68200\n",
      "[Epoch 1570/2000] train_loss = 0.28182, train_acc = 0.97667, val_acc = 0.69400\n",
      "[Epoch 1580/2000] train_loss = 0.28822, train_acc = 0.97000, val_acc = 0.69400\n",
      "[Epoch 1590/2000] train_loss = 0.29230, train_acc = 0.94667, val_acc = 0.69200\n",
      "[Epoch 1600/2000] train_loss = 0.30001, train_acc = 0.95000, val_acc = 0.69600\n",
      "[Epoch 1610/2000] train_loss = 0.29051, train_acc = 0.97000, val_acc = 0.67800\n",
      "[Epoch 1620/2000] train_loss = 0.28322, train_acc = 0.97000, val_acc = 0.68600\n",
      "[Epoch 1630/2000] train_loss = 0.28423, train_acc = 0.97333, val_acc = 0.70000\n",
      "[Epoch 1640/2000] train_loss = 0.28585, train_acc = 0.96000, val_acc = 0.69000\n",
      "[Epoch 1650/2000] train_loss = 0.27602, train_acc = 0.98000, val_acc = 0.69200\n",
      "[Epoch 1660/2000] train_loss = 0.27176, train_acc = 0.96333, val_acc = 0.69000\n",
      "[Epoch 1670/2000] train_loss = 0.26035, train_acc = 0.98667, val_acc = 0.69200\n",
      "[Epoch 1680/2000] train_loss = 0.27703, train_acc = 0.97333, val_acc = 0.68400\n",
      "[Epoch 1690/2000] train_loss = 0.28551, train_acc = 0.96000, val_acc = 0.68400\n",
      "[Epoch 1700/2000] train_loss = 0.26446, train_acc = 0.97667, val_acc = 0.67800\n",
      "[Epoch 1710/2000] train_loss = 0.28838, train_acc = 0.96667, val_acc = 0.68800\n",
      "[Epoch 1720/2000] train_loss = 0.27196, train_acc = 0.97000, val_acc = 0.70000\n",
      "[Epoch 1730/2000] train_loss = 0.27627, train_acc = 0.96667, val_acc = 0.67800\n",
      "[Epoch 1740/2000] train_loss = 0.28273, train_acc = 0.97000, val_acc = 0.69800\n",
      "[Epoch 1750/2000] train_loss = 0.29723, train_acc = 0.97333, val_acc = 0.69200\n",
      "[Epoch 1760/2000] train_loss = 0.27807, train_acc = 0.97000, val_acc = 0.69200\n",
      "[Epoch 1770/2000] train_loss = 0.27147, train_acc = 0.96667, val_acc = 0.69400\n",
      "[Epoch 1780/2000] train_loss = 0.27755, train_acc = 0.97000, val_acc = 0.69200\n",
      "[Epoch 1790/2000] train_loss = 0.26785, train_acc = 0.97333, val_acc = 0.69400\n",
      "[Epoch 1800/2000] train_loss = 0.26880, train_acc = 0.95667, val_acc = 0.70200\n",
      "[Epoch 1810/2000] train_loss = 0.27613, train_acc = 0.96333, val_acc = 0.68600\n",
      "[Epoch 1820/2000] train_loss = 0.26785, train_acc = 0.97000, val_acc = 0.68800\n",
      "[Epoch 1830/2000] train_loss = 0.27547, train_acc = 0.97667, val_acc = 0.67600\n",
      "[Epoch 1840/2000] train_loss = 0.28615, train_acc = 0.95667, val_acc = 0.70200\n",
      "[Epoch 1850/2000] train_loss = 0.26239, train_acc = 0.96000, val_acc = 0.70000\n",
      "[Epoch 1860/2000] train_loss = 0.27701, train_acc = 0.95333, val_acc = 0.69200\n",
      "[Epoch 1870/2000] train_loss = 0.27311, train_acc = 0.97000, val_acc = 0.71800\n",
      "[Epoch 1880/2000] train_loss = 0.27222, train_acc = 0.96667, val_acc = 0.69800\n",
      "[Epoch 1890/2000] train_loss = 0.27306, train_acc = 0.95667, val_acc = 0.69400\n",
      "[Epoch 1900/2000] train_loss = 0.27770, train_acc = 0.96667, val_acc = 0.68600\n",
      "[Epoch 1910/2000] train_loss = 0.28437, train_acc = 0.96000, val_acc = 0.68600\n",
      "[Epoch 1920/2000] train_loss = 0.26324, train_acc = 0.97667, val_acc = 0.69400\n",
      "[Epoch 1930/2000] train_loss = 0.25597, train_acc = 0.98000, val_acc = 0.69600\n",
      "[Epoch 1940/2000] train_loss = 0.27509, train_acc = 0.97333, val_acc = 0.69000\n",
      "[Epoch 1950/2000] train_loss = 0.26972, train_acc = 0.97333, val_acc = 0.68000\n",
      "[Epoch 1960/2000] train_loss = 0.25140, train_acc = 0.97667, val_acc = 0.69400\n",
      "[Epoch 1970/2000] train_loss = 0.25755, train_acc = 0.97667, val_acc = 0.71200\n",
      "[Epoch 1980/2000] train_loss = 0.27059, train_acc = 0.96667, val_acc = 0.69200\n",
      "[Epoch 1990/2000] train_loss = 0.25026, train_acc = 0.97667, val_acc = 0.69800\n",
      "[Epoch 2000/2000] train_loss = 0.27484, train_acc = 0.95667, val_acc = 0.70000\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "learning_rate = 2e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=5e-4)\n",
    "Loss = nn.CrossEntropyLoss()\n",
    "epochs = 2000\n",
    "start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data.x, data.edge_index)\n",
    "    loss = Loss(output[train_id], data.y[train_id].squeeze())\n",
    "    train_acc = cal_acc(output[train_id], data.y[train_id].squeeze())\n",
    "    val_acc = cal_acc(output[val_id], data.y[val_id].squeeze())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print('[Epoch {}/{}] train_loss = {:.5f}, train_acc = {:.5f}, val_acc = {:.5f}'.format(epoch + 1, epochs, loss, train_acc, val_acc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PPI(path, split = 'train')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './ppi/'\n",
    "train_dataset = PPI(path, split = 'train')\n",
    "val_dataset = PPI(path, split = 'val')\n",
    "test_dataset = PPI(path, split = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[1767, 50], edge_index=[2, 32318], y=[1767, 121])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PPI(path)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_num = 2\n",
    "input_size = x.shape[1]\n",
    "output_size = label_num\n",
    "layer_size = 256\n",
    "dropout_rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, dataset, num_layers, hidden):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_features, hidden)\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for i in range(num_layers - 1):\n",
    "            self.convs.append(GCNConv(hidden, hidden))\n",
    "        self.lin1 = nn.Linear(hidden, hidden)\n",
    "        self.lin2 = nn.Linear(hidden, dataset.num_classes)\n",
    "        # print('GCN')\n",
    "\n",
    "    # def reset_parameters(self):\n",
    "    #     self.conv1.reset_parameters()\n",
    "    #     for conv in self.convs:\n",
    "    #         conv.reset_parameters()\n",
    "    #     self.lin1.reset_parameters()\n",
    "    #     self.lin2.reset_parameters()\n",
    "\n",
    "    def forward(self, dataX, dataY):\n",
    "        activation = F.relu  # torch.sigmoid\n",
    "        x, edge_index = dataX, dataY\n",
    "        x = activation(self.conv1(x, edge_index))\n",
    "        for conv in self.convs:\n",
    "            x = activation(conv(x, edge_index))\n",
    "        #x = global_mean_pool(x, batch)\n",
    "        x = activation(self.lin1(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "        x = F.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(train_dataset, hidden_layer_num, layer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_acc_ppi(y_pred, y_true):\n",
    "    correct = torch.eq(torch.round(y_pred), y_true).float()\n",
    "    acc = correct.sum(dim=1) / len(correct[0])\n",
    "    return ((torch.round(y_pred)) == y_true).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_loss_and_acc(loader):\n",
    "    total_l1 = 0\n",
    "    total_loss = 0\n",
    "    total_examples = 0\n",
    "    for i, data in enumerate(loader, 0):\n",
    "        data = data.to(device)\n",
    "        print(len(data.x))\n",
    "        output = model(data.x, data.edge_index)\n",
    "        acc = cal_acc_ppi(output, data.y)\n",
    "        total_l1 += acc * data.num_nodes\n",
    "        total_loss += loss.item() * data.num_nodes\n",
    "        total_examples += data.num_nodes\n",
    "    return total_loss / total_examples, total_l1 / total_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/wangyy/anaconda3/envs/pyg/lib/python3.7/site-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1767\n",
      "1021\n",
      "2401\n",
      "1823\n",
      "3312\n",
      "591\n",
      "2815\n",
      "1878\n",
      "2263\n",
      "3021\n",
      "3480\n",
      "2326\n",
      "2650\n",
      "1819\n",
      "3163\n",
      "2339\n",
      "1377\n",
      "1578\n",
      "2488\n",
      "2794\n",
      "6514\n",
      "[Epoch 1/2000] train_loss = 0.69346 train_acc = 0.50736 val_loss = 0.69346 val_acc = 0.50749\n",
      "1767\n",
      "1578\n",
      "3163\n",
      "2488\n",
      "2815\n",
      "3480\n",
      "1878\n",
      "591\n",
      "1377\n",
      "1021\n",
      "1823\n",
      "1819\n",
      "3021\n",
      "2794\n",
      "3312\n",
      "2263\n",
      "2339\n",
      "2326\n",
      "2401\n",
      "2650\n",
      "6514\n",
      "[Epoch 2/2000] train_loss = 0.69299 train_acc = 0.51536 val_loss = 0.69299 val_acc = 0.51616\n",
      "1377\n",
      "2326\n",
      "2815\n",
      "3021\n",
      "3480\n",
      "1819\n",
      "1578\n",
      "1021\n",
      "2488\n",
      "591\n",
      "2401\n",
      "1823\n",
      "3163\n",
      "1767\n",
      "2650\n",
      "1878\n",
      "2263\n",
      "2339\n",
      "2794\n",
      "3312\n",
      "6514\n",
      "[Epoch 3/2000] train_loss = 0.69251 train_acc = 0.52366 val_loss = 0.69251 val_acc = 0.52509\n",
      "591\n",
      "3163\n",
      "2650\n",
      "1819\n",
      "2401\n",
      "2488\n",
      "2263\n",
      "3312\n",
      "3480\n",
      "3021\n",
      "2326\n",
      "1578\n",
      "2339\n",
      "1878\n",
      "1767\n",
      "2815\n",
      "1021\n",
      "2794\n",
      "1377\n",
      "1823\n",
      "6514\n",
      "[Epoch 4/2000] train_loss = 0.69216 train_acc = 0.53154 val_loss = 0.69216 val_acc = 0.53376\n",
      "1021\n",
      "1767\n",
      "3163\n",
      "1819\n",
      "2401\n",
      "1377\n",
      "1823\n",
      "2339\n",
      "3480\n",
      "1878\n",
      "2650\n",
      "2263\n",
      "2488\n",
      "3312\n",
      "591\n",
      "2326\n",
      "2794\n",
      "3021\n",
      "2815\n",
      "1578\n",
      "6514\n",
      "[Epoch 5/2000] train_loss = 0.69186 train_acc = 0.53865 val_loss = 0.69186 val_acc = 0.54119\n",
      "2263\n",
      "2401\n",
      "1823\n",
      "1767\n",
      "2326\n",
      "2488\n",
      "2650\n",
      "591\n",
      "2794\n",
      "3312\n",
      "3480\n",
      "3163\n",
      "1021\n",
      "1819\n",
      "2339\n",
      "1377\n",
      "1578\n",
      "2815\n",
      "3021\n",
      "1878\n",
      "6514\n",
      "[Epoch 6/2000] train_loss = 0.69159 train_acc = 0.54497 val_loss = 0.69159 val_acc = 0.54759\n",
      "2263\n",
      "2339\n",
      "2794\n",
      "591\n",
      "3021\n",
      "1878\n",
      "3480\n",
      "2488\n",
      "2815\n",
      "3312\n",
      "1823\n",
      "2401\n",
      "1377\n",
      "1578\n",
      "1767\n",
      "2650\n",
      "1819\n",
      "2326\n",
      "3163\n",
      "1021\n",
      "6514\n",
      "[Epoch 7/2000] train_loss = 0.69111 train_acc = 0.55110 val_loss = 0.69111 val_acc = 0.55382\n",
      "2339\n",
      "2326\n",
      "2815\n",
      "3312\n",
      "3480\n",
      "1021\n",
      "1823\n",
      "2488\n",
      "1819\n",
      "1767\n",
      "1878\n",
      "3021\n",
      "591\n",
      "1578\n",
      "3163\n",
      "2401\n",
      "2650\n",
      "1377\n",
      "2263\n",
      "2794\n",
      "6514\n",
      "[Epoch 8/2000] train_loss = 0.69085 train_acc = 0.55708 val_loss = 0.69085 val_acc = 0.55977\n",
      "3312\n",
      "1578\n",
      "2794\n",
      "2263\n",
      "2650\n",
      "591\n",
      "2401\n",
      "1377\n",
      "1823\n",
      "1878\n",
      "3480\n",
      "2339\n",
      "3021\n",
      "1767\n",
      "1021\n",
      "3163\n",
      "2815\n",
      "1819\n",
      "2488\n",
      "2326\n",
      "6514\n",
      "[Epoch 9/2000] train_loss = 0.69053 train_acc = 0.56166 val_loss = 0.69053 val_acc = 0.56441\n",
      "1878\n",
      "2488\n",
      "2401\n",
      "3480\n",
      "2326\n",
      "591\n",
      "2815\n",
      "1377\n",
      "1819\n",
      "1021\n",
      "1823\n",
      "2263\n",
      "1767\n",
      "3163\n",
      "1578\n",
      "2339\n",
      "3312\n",
      "2650\n",
      "2794\n",
      "3021\n",
      "6514\n",
      "[Epoch 10/2000] train_loss = 0.69017 train_acc = 0.56532 val_loss = 0.69017 val_acc = 0.56772\n",
      "2794\n",
      "3480\n",
      "1878\n",
      "2650\n",
      "2339\n",
      "1823\n",
      "3163\n",
      "1377\n",
      "2263\n",
      "1578\n",
      "591\n",
      "2401\n",
      "3021\n",
      "2815\n",
      "2326\n",
      "1767\n",
      "2488\n",
      "1021\n",
      "3312\n",
      "1819\n",
      "6514\n",
      "[Epoch 11/2000] train_loss = 0.68970 train_acc = 0.56938 val_loss = 0.68970 val_acc = 0.57167\n",
      "3163\n",
      "1767\n",
      "1819\n",
      "2650\n",
      "2794\n",
      "1578\n",
      "2488\n",
      "1823\n",
      "2339\n",
      "591\n",
      "2815\n",
      "2401\n",
      "1377\n",
      "2326\n",
      "3021\n",
      "1021\n",
      "3312\n",
      "1878\n",
      "3480\n",
      "2263\n",
      "6514\n",
      "[Epoch 12/2000] train_loss = 0.68906 train_acc = 0.57424 val_loss = 0.68906 val_acc = 0.57644\n",
      "1021\n",
      "1819\n",
      "3163\n",
      "2339\n",
      "1823\n",
      "3021\n",
      "3480\n",
      "2263\n",
      "2650\n",
      "1377\n",
      "2794\n",
      "2401\n",
      "1878\n",
      "3312\n",
      "2488\n",
      "591\n",
      "2815\n",
      "2326\n",
      "1578\n",
      "1767\n",
      "6514\n",
      "[Epoch 13/2000] train_loss = 0.68884 train_acc = 0.57970 val_loss = 0.68884 val_acc = 0.58199\n",
      "2263\n",
      "2401\n",
      "1021\n",
      "3021\n",
      "591\n",
      "2488\n",
      "3480\n",
      "1823\n",
      "2815\n",
      "1819\n",
      "3163\n",
      "2326\n",
      "1767\n",
      "2650\n",
      "3312\n",
      "1878\n",
      "1377\n",
      "1578\n",
      "2339\n",
      "2794\n",
      "6514\n",
      "[Epoch 14/2000] train_loss = 0.68811 train_acc = 0.58584 val_loss = 0.68811 val_acc = 0.58795\n",
      "1819\n",
      "3021\n",
      "3312\n",
      "2263\n",
      "591\n",
      "2794\n",
      "1823\n",
      "1767\n",
      "1021\n",
      "1578\n",
      "1377\n",
      "2339\n",
      "1878\n",
      "2326\n",
      "2815\n",
      "2401\n",
      "3163\n",
      "2488\n",
      "2650\n",
      "3480\n",
      "6514\n",
      "[Epoch 15/2000] train_loss = 0.68742 train_acc = 0.59262 val_loss = 0.68742 val_acc = 0.59482\n",
      "591\n",
      "1021\n",
      "2815\n",
      "1767\n",
      "2326\n",
      "2650\n",
      "1819\n",
      "1578\n",
      "3312\n",
      "1377\n",
      "1823\n",
      "1878\n",
      "2488\n",
      "3163\n",
      "2794\n",
      "3021\n",
      "2339\n",
      "3480\n",
      "2263\n",
      "2401\n",
      "6514\n",
      "[Epoch 16/2000] train_loss = 0.68684 train_acc = 0.60059 val_loss = 0.68684 val_acc = 0.60236\n",
      "2339\n",
      "591\n",
      "3021\n",
      "2401\n",
      "3480\n",
      "1823\n",
      "3163\n",
      "1878\n",
      "1377\n",
      "1578\n",
      "2650\n",
      "2815\n",
      "3312\n",
      "1819\n",
      "2263\n",
      "2794\n",
      "2488\n",
      "1021\n",
      "2326\n",
      "1767\n",
      "6514\n",
      "[Epoch 17/2000] train_loss = 0.68620 train_acc = 0.60933 val_loss = 0.68620 val_acc = 0.61115\n",
      "1377\n",
      "3312\n",
      "2488\n",
      "2815\n",
      "3480\n",
      "1021\n",
      "3021\n",
      "1578\n",
      "2263\n",
      "2339\n",
      "1819\n",
      "3163\n",
      "1823\n",
      "2650\n",
      "2401\n",
      "2794\n",
      "1878\n",
      "591\n",
      "2326\n",
      "1767\n",
      "6514\n",
      "[Epoch 18/2000] train_loss = 0.68589 train_acc = 0.61912 val_loss = 0.68589 val_acc = 0.62136\n",
      "1823\n",
      "1819\n",
      "2650\n",
      "3480\n",
      "2794\n",
      "2339\n",
      "1767\n",
      "2326\n",
      "3312\n",
      "1021\n",
      "2263\n",
      "3163\n",
      "2488\n",
      "2815\n",
      "1377\n",
      "1578\n",
      "591\n",
      "2401\n",
      "1878\n",
      "3021\n",
      "6514\n",
      "[Epoch 19/2000] train_loss = 0.68474 train_acc = 0.62883 val_loss = 0.68474 val_acc = 0.63139\n",
      "3480\n",
      "1767\n",
      "591\n",
      "2339\n",
      "1578\n",
      "1021\n",
      "3163\n",
      "2815\n",
      "2401\n",
      "1878\n",
      "2326\n",
      "1823\n",
      "2794\n",
      "2650\n",
      "1819\n",
      "2488\n",
      "1377\n",
      "3021\n",
      "3312\n",
      "2263\n",
      "6514\n",
      "[Epoch 20/2000] train_loss = 0.68426 train_acc = 0.63823 val_loss = 0.68426 val_acc = 0.64113\n",
      "2815\n",
      "3480\n",
      "2650\n",
      "1021\n",
      "2794\n",
      "2263\n",
      "1377\n",
      "2488\n",
      "1819\n",
      "2339\n",
      "1823\n",
      "1767\n",
      "591\n",
      "2401\n",
      "3021\n",
      "2326\n",
      "1878\n",
      "1578\n",
      "3163\n",
      "3312\n",
      "6514\n",
      "[Epoch 21/2000] train_loss = 0.68278 train_acc = 0.64753 val_loss = 0.68278 val_acc = 0.65051\n",
      "1878\n",
      "2794\n",
      "3021\n",
      "591\n",
      "3480\n",
      "1767\n",
      "2650\n",
      "1819\n",
      "2339\n",
      "2263\n",
      "1377\n",
      "1823\n",
      "2326\n",
      "2815\n",
      "2401\n",
      "3312\n",
      "3163\n",
      "1021\n",
      "2488\n",
      "1578\n",
      "6514\n",
      "[Epoch 22/2000] train_loss = 0.68222 train_acc = 0.65803 val_loss = 0.68222 val_acc = 0.66128\n",
      "3021\n",
      "2263\n",
      "1819\n",
      "2650\n",
      "2326\n",
      "1021\n",
      "1578\n",
      "1767\n",
      "2488\n",
      "1878\n",
      "2401\n",
      "3163\n",
      "3312\n",
      "1823\n",
      "1377\n",
      "2815\n",
      "591\n",
      "3480\n",
      "2339\n",
      "2794\n",
      "6514\n",
      "[Epoch 23/2000] train_loss = 0.68082 train_acc = 0.66887 val_loss = 0.68082 val_acc = 0.67266\n",
      "2263\n",
      "2339\n",
      "2815\n",
      "1021\n",
      "2488\n",
      "3312\n",
      "2794\n",
      "1819\n",
      "2401\n",
      "1377\n",
      "3163\n",
      "2326\n",
      "3480\n",
      "3021\n",
      "1578\n",
      "1878\n",
      "591\n",
      "1823\n",
      "1767\n",
      "2650\n",
      "6514\n",
      "[Epoch 24/2000] train_loss = 0.67981 train_acc = 0.67981 val_loss = 0.67981 val_acc = 0.68433\n",
      "2815\n",
      "3163\n",
      "2326\n",
      "1819\n",
      "591\n",
      "2263\n",
      "1377\n",
      "2401\n",
      "2650\n",
      "1021\n",
      "1823\n",
      "3480\n",
      "1578\n",
      "3021\n",
      "2794\n",
      "2488\n",
      "1767\n",
      "3312\n",
      "1878\n",
      "2339\n",
      "6514\n",
      "[Epoch 25/2000] train_loss = 0.67833 train_acc = 0.69036 val_loss = 0.67833 val_acc = 0.69529\n",
      "1578\n",
      "1767\n",
      "1021\n",
      "3480\n",
      "2650\n",
      "2794\n",
      "2815\n",
      "1819\n",
      "1878\n",
      "2326\n",
      "2263\n",
      "3312\n",
      "2401\n",
      "591\n",
      "2339\n",
      "1823\n",
      "3163\n",
      "3021\n",
      "1377\n",
      "2488\n",
      "6514\n",
      "[Epoch 26/2000] train_loss = 0.67729 train_acc = 0.69962 val_loss = 0.67729 val_acc = 0.70522\n",
      "3021\n",
      "1823\n",
      "1767\n",
      "2401\n",
      "2263\n",
      "1578\n",
      "2815\n",
      "1819\n",
      "3163\n",
      "1377\n",
      "3312\n",
      "2326\n",
      "2794\n",
      "2650\n",
      "1021\n",
      "2488\n",
      "1878\n",
      "591\n",
      "3480\n",
      "2339\n",
      "6514\n",
      "[Epoch 27/2000] train_loss = 0.67482 train_acc = 0.70737 val_loss = 0.67482 val_acc = 0.71347\n",
      "1578\n",
      "3163\n",
      "1878\n",
      "3021\n",
      "1819\n",
      "3312\n",
      "2263\n",
      "1767\n",
      "2794\n",
      "2339\n",
      "591\n",
      "2650\n",
      "2401\n",
      "1021\n",
      "1377\n",
      "2488\n",
      "2815\n",
      "3480\n",
      "2326\n",
      "1823\n",
      "6514\n",
      "[Epoch 28/2000] train_loss = 0.66729 train_acc = 0.71392 val_loss = 0.66729 val_acc = 0.72019\n",
      "591\n",
      "3021\n",
      "3312\n",
      "3480\n",
      "2815\n",
      "1377\n",
      "2488\n",
      "1021\n",
      "1767\n",
      "1578\n",
      "1819\n",
      "1823\n",
      "2326\n",
      "1878\n",
      "2794\n",
      "2401\n",
      "3163\n",
      "2339\n",
      "2263\n",
      "2650\n",
      "6514\n",
      "[Epoch 29/2000] train_loss = 0.67197 train_acc = 0.72012 val_loss = 0.67197 val_acc = 0.72680\n",
      "2401\n",
      "591\n",
      "1767\n",
      "2488\n",
      "3312\n",
      "1578\n",
      "1878\n",
      "2263\n",
      "2339\n",
      "2815\n",
      "2794\n",
      "3163\n",
      "3480\n",
      "3021\n",
      "1377\n",
      "2650\n",
      "1021\n",
      "1823\n",
      "2326\n",
      "1819\n",
      "6514\n",
      "[Epoch 30/2000] train_loss = 0.66200 train_acc = 0.72505 val_loss = 0.66200 val_acc = 0.73233\n",
      "2650\n",
      "1377\n",
      "591\n",
      "3480\n",
      "1823\n",
      "3312\n",
      "1021\n",
      "2815\n",
      "1767\n",
      "2326\n",
      "1878\n",
      "1819\n",
      "2401\n",
      "2339\n",
      "3163\n",
      "2488\n",
      "2263\n",
      "2794\n",
      "1578\n",
      "3021\n",
      "6514\n",
      "[Epoch 31/2000] train_loss = 0.66719 train_acc = 0.72860 val_loss = 0.66719 val_acc = 0.73655\n",
      "1578\n",
      "1878\n",
      "3163\n",
      "1377\n",
      "2794\n",
      "2263\n",
      "1021\n",
      "3480\n",
      "2488\n",
      "591\n",
      "2650\n",
      "1767\n",
      "2339\n",
      "2326\n",
      "3021\n",
      "2401\n",
      "3312\n",
      "1819\n",
      "1823\n",
      "2815\n",
      "6514\n",
      "[Epoch 32/2000] train_loss = 0.66546 train_acc = 0.73074 val_loss = 0.66546 val_acc = 0.73919\n",
      "2401\n",
      "1578\n",
      "1377\n",
      "3021\n",
      "3312\n",
      "1021\n",
      "2650\n",
      "2326\n",
      "2815\n",
      "3480\n",
      "2794\n",
      "1878\n",
      "2263\n",
      "591\n",
      "1823\n",
      "1767\n",
      "3163\n",
      "1819\n",
      "2488\n",
      "2339\n",
      "6514\n",
      "[Epoch 33/2000] train_loss = 0.66144 train_acc = 0.73238 val_loss = 0.66144 val_acc = 0.74099\n",
      "2650\n",
      "2263\n",
      "3312\n",
      "1377\n",
      "2794\n",
      "2326\n",
      "1823\n",
      "591\n",
      "2339\n",
      "1021\n",
      "3021\n",
      "1767\n",
      "1819\n",
      "2488\n",
      "1578\n",
      "2815\n",
      "3480\n",
      "2401\n",
      "3163\n",
      "1878\n",
      "6514\n",
      "[Epoch 34/2000] train_loss = 0.65980 train_acc = 0.73421 val_loss = 0.65980 val_acc = 0.74280\n",
      "2401\n",
      "1767\n",
      "2263\n",
      "2339\n",
      "1578\n",
      "2815\n",
      "3480\n",
      "1819\n",
      "3021\n",
      "1021\n",
      "3312\n",
      "2488\n",
      "2794\n",
      "1878\n",
      "591\n",
      "1377\n",
      "2326\n",
      "1823\n",
      "2650\n",
      "3163\n",
      "6514\n",
      "[Epoch 35/2000] train_loss = 0.65733 train_acc = 0.73601 val_loss = 0.65733 val_acc = 0.74473\n",
      "3312\n",
      "3163\n",
      "2815\n",
      "2339\n",
      "1878\n",
      "2263\n",
      "1377\n",
      "2401\n",
      "1578\n",
      "2794\n",
      "1767\n",
      "3021\n",
      "2488\n",
      "591\n",
      "1021\n",
      "1823\n",
      "3480\n",
      "1819\n",
      "2326\n",
      "2650\n",
      "6514\n",
      "[Epoch 36/2000] train_loss = 0.65440 train_acc = 0.73696 val_loss = 0.65440 val_acc = 0.74582\n",
      "1578\n",
      "1878\n",
      "1767\n",
      "1377\n",
      "2401\n",
      "3312\n",
      "3480\n",
      "2794\n",
      "591\n",
      "2815\n",
      "3163\n",
      "1021\n",
      "1823\n",
      "1819\n",
      "2650\n",
      "2326\n",
      "2339\n",
      "2263\n",
      "2488\n",
      "3021\n",
      "6514\n",
      "[Epoch 37/2000] train_loss = 0.64866 train_acc = 0.73728 val_loss = 0.64866 val_acc = 0.74629\n",
      "2794\n",
      "3021\n",
      "1021\n",
      "1823\n",
      "1377\n",
      "2401\n",
      "1819\n",
      "2339\n",
      "3480\n",
      "2650\n",
      "3312\n",
      "1767\n",
      "2326\n",
      "2488\n",
      "3163\n",
      "1578\n",
      "1878\n",
      "2263\n",
      "2815\n",
      "591\n",
      "6514\n",
      "[Epoch 38/2000] train_loss = 0.64563 train_acc = 0.73729 val_loss = 0.64563 val_acc = 0.74632\n",
      "1819\n",
      "3021\n",
      "2263\n",
      "2339\n",
      "1823\n",
      "2815\n",
      "2401\n",
      "1878\n",
      "3480\n",
      "3163\n",
      "1021\n",
      "2650\n",
      "2794\n",
      "1578\n",
      "1767\n",
      "3312\n",
      "2326\n",
      "1377\n",
      "2488\n",
      "591\n",
      "6514\n",
      "[Epoch 39/2000] train_loss = 0.64194 train_acc = 0.73734 val_loss = 0.64194 val_acc = 0.74632\n",
      "2794\n",
      "1819\n",
      "1377\n",
      "2488\n",
      "3021\n",
      "591\n",
      "2326\n",
      "2401\n",
      "1021\n",
      "3163\n",
      "3480\n",
      "3312\n",
      "1823\n",
      "1878\n",
      "2650\n",
      "1578\n",
      "1767\n",
      "2815\n",
      "2339\n",
      "2263\n",
      "6514\n",
      "[Epoch 40/2000] train_loss = 0.64189 train_acc = 0.73750 val_loss = 0.64189 val_acc = 0.74645\n",
      "1767\n",
      "3021\n",
      "2815\n",
      "1377\n",
      "2326\n",
      "3480\n",
      "3163\n",
      "1578\n",
      "2488\n",
      "1878\n",
      "2794\n",
      "2339\n",
      "1819\n",
      "2401\n",
      "1021\n",
      "2263\n",
      "2650\n",
      "1823\n",
      "3312\n",
      "591\n",
      "6514\n",
      "[Epoch 41/2000] train_loss = 0.63526 train_acc = 0.73761 val_loss = 0.63526 val_acc = 0.74656\n",
      "591\n",
      "3312\n",
      "1021\n",
      "2339\n",
      "2326\n",
      "3480\n",
      "1819\n",
      "2488\n",
      "1767\n",
      "1823\n",
      "2794\n",
      "2401\n",
      "2263\n",
      "2650\n",
      "3021\n",
      "3163\n",
      "1878\n",
      "1377\n",
      "1578\n",
      "2815\n",
      "6514\n",
      "[Epoch 42/2000] train_loss = 0.63181 train_acc = 0.73771 val_loss = 0.63181 val_acc = 0.74660\n",
      "1823\n",
      "1021\n",
      "3163\n",
      "2326\n",
      "3312\n",
      "1578\n",
      "1819\n",
      "1767\n",
      "2339\n",
      "591\n",
      "1377\n",
      "2263\n",
      "3021\n",
      "1878\n",
      "3480\n",
      "2650\n",
      "2401\n",
      "2488\n",
      "2815\n",
      "2794\n",
      "6514\n",
      "[Epoch 43/2000] train_loss = 0.62856 train_acc = 0.73763 val_loss = 0.62856 val_acc = 0.74650\n",
      "2815\n",
      "3312\n",
      "1767\n",
      "2263\n",
      "2401\n",
      "3021\n",
      "3163\n",
      "2488\n",
      "2794\n",
      "2339\n",
      "1823\n",
      "2326\n",
      "1377\n",
      "591\n",
      "1578\n",
      "3480\n",
      "2650\n",
      "1021\n",
      "1819\n",
      "1878\n",
      "6514\n",
      "[Epoch 44/2000] train_loss = 0.62209 train_acc = 0.73748 val_loss = 0.62209 val_acc = 0.74636\n",
      "1021\n",
      "3163\n",
      "2326\n",
      "1767\n",
      "2815\n",
      "1377\n",
      "3312\n",
      "2401\n",
      "2488\n",
      "2794\n",
      "2650\n",
      "591\n",
      "1823\n",
      "1578\n",
      "1878\n",
      "2263\n",
      "3480\n",
      "2339\n",
      "3021\n",
      "1819\n",
      "6514\n",
      "[Epoch 45/2000] train_loss = 0.62153 train_acc = 0.73739 val_loss = 0.62153 val_acc = 0.74619\n",
      "2815\n",
      "1578\n",
      "1021\n",
      "1377\n",
      "3480\n",
      "2794\n",
      "3163\n",
      "3312\n",
      "2339\n",
      "1819\n",
      "1823\n",
      "3021\n",
      "1878\n",
      "2650\n",
      "2326\n",
      "591\n",
      "2401\n",
      "2488\n",
      "1767\n",
      "2263\n",
      "6514\n",
      "[Epoch 46/2000] train_loss = 0.61817 train_acc = 0.73745 val_loss = 0.61817 val_acc = 0.74618\n",
      "2263\n",
      "3480\n",
      "3163\n",
      "1578\n",
      "2326\n",
      "2488\n",
      "1767\n",
      "1021\n",
      "3312\n",
      "1878\n",
      "2650\n",
      "1377\n",
      "2794\n",
      "1819\n",
      "2401\n",
      "2815\n",
      "591\n",
      "3021\n",
      "1823\n",
      "2339\n",
      "6514\n",
      "[Epoch 47/2000] train_loss = 0.61874 train_acc = 0.73756 val_loss = 0.61874 val_acc = 0.74622\n",
      "3480\n",
      "2815\n",
      "2339\n",
      "3312\n",
      "1823\n",
      "1819\n",
      "2401\n",
      "2263\n",
      "3021\n",
      "2326\n",
      "2794\n",
      "3163\n",
      "1878\n",
      "591\n",
      "2488\n",
      "1021\n",
      "1767\n",
      "2650\n",
      "1578\n",
      "1377\n",
      "6514\n",
      "[Epoch 48/2000] train_loss = 0.61650 train_acc = 0.73770 val_loss = 0.61650 val_acc = 0.74630\n",
      "1819\n",
      "3312\n",
      "3163\n",
      "1021\n",
      "1878\n",
      "1767\n",
      "3021\n",
      "2263\n",
      "1823\n",
      "3480\n",
      "591\n",
      "1377\n",
      "2326\n",
      "2650\n",
      "2815\n",
      "2339\n",
      "1578\n",
      "2488\n",
      "2401\n",
      "2794\n",
      "6514\n",
      "[Epoch 49/2000] train_loss = 0.61444 train_acc = 0.73774 val_loss = 0.61444 val_acc = 0.74637\n",
      "2794\n",
      "2263\n",
      "1819\n",
      "3480\n",
      "1021\n",
      "2326\n",
      "2488\n",
      "1878\n",
      "2339\n",
      "2401\n",
      "1823\n",
      "2650\n",
      "1377\n",
      "591\n",
      "3021\n",
      "1578\n",
      "2815\n",
      "1767\n",
      "3163\n",
      "3312\n",
      "6514\n",
      "[Epoch 50/2000] train_loss = 0.60374 train_acc = 0.73732 val_loss = 0.60374 val_acc = 0.74592\n",
      "2263\n",
      "3312\n",
      "3163\n",
      "1021\n",
      "591\n",
      "2401\n",
      "2815\n",
      "2650\n",
      "2488\n",
      "1819\n",
      "1823\n",
      "1578\n",
      "1377\n",
      "2794\n",
      "3021\n",
      "2339\n",
      "2326\n",
      "3480\n",
      "1878\n",
      "1767\n",
      "6514\n",
      "[Epoch 51/2000] train_loss = 0.62910 train_acc = 0.73728 val_loss = 0.62910 val_acc = 0.74588\n",
      "3021\n",
      "3163\n",
      "2263\n",
      "1823\n",
      "1878\n",
      "2815\n",
      "2488\n",
      "1819\n",
      "2339\n",
      "3312\n",
      "2650\n",
      "2401\n",
      "3480\n",
      "2794\n",
      "1021\n",
      "2326\n",
      "1377\n",
      "1578\n",
      "1767\n",
      "591\n",
      "6514\n",
      "[Epoch 52/2000] train_loss = 0.60178 train_acc = 0.73684 val_loss = 0.60178 val_acc = 0.74534\n",
      "2794\n",
      "1767\n",
      "3312\n",
      "1878\n",
      "2815\n",
      "1823\n",
      "1819\n",
      "3163\n",
      "1578\n",
      "2339\n",
      "1021\n",
      "591\n",
      "3021\n",
      "2263\n",
      "2401\n",
      "2650\n",
      "1377\n",
      "2488\n",
      "2326\n",
      "3480\n",
      "6514\n",
      "[Epoch 53/2000] train_loss = 0.60687 train_acc = 0.73671 val_loss = 0.60687 val_acc = 0.74518\n",
      "3163\n",
      "2815\n",
      "2263\n",
      "3480\n",
      "1767\n",
      "1377\n",
      "3021\n",
      "1578\n",
      "2650\n",
      "2401\n",
      "2488\n",
      "2794\n",
      "1819\n",
      "1823\n",
      "1878\n",
      "2326\n",
      "2339\n",
      "591\n",
      "1021\n",
      "3312\n",
      "6514\n",
      "[Epoch 54/2000] train_loss = 0.60106 train_acc = 0.73666 val_loss = 0.60106 val_acc = 0.74512\n",
      "2326\n",
      "1021\n",
      "1377\n",
      "3480\n",
      "2650\n",
      "2263\n",
      "1578\n",
      "2339\n",
      "1878\n",
      "3021\n",
      "2815\n",
      "3312\n",
      "2794\n",
      "591\n",
      "3163\n",
      "2488\n",
      "1819\n",
      "1767\n",
      "2401\n",
      "1823\n",
      "6514\n",
      "[Epoch 55/2000] train_loss = 0.59221 train_acc = 0.73661 val_loss = 0.59221 val_acc = 0.74505\n",
      "2339\n",
      "591\n",
      "2326\n",
      "3312\n",
      "2488\n",
      "2815\n",
      "2794\n",
      "3163\n",
      "1878\n",
      "1823\n",
      "1377\n",
      "2263\n",
      "2650\n",
      "1819\n",
      "1767\n",
      "3480\n",
      "1021\n",
      "3021\n",
      "1578\n",
      "2401\n",
      "6514\n",
      "[Epoch 56/2000] train_loss = 0.63244 train_acc = 0.73654 val_loss = 0.63244 val_acc = 0.74496\n",
      "2326\n",
      "2650\n",
      "2488\n",
      "591\n",
      "1878\n",
      "3312\n",
      "1819\n",
      "2401\n",
      "3163\n",
      "1823\n",
      "2339\n",
      "3021\n",
      "1767\n",
      "3480\n",
      "2815\n",
      "1021\n",
      "1377\n",
      "1578\n",
      "2794\n",
      "2263\n",
      "6514\n",
      "[Epoch 57/2000] train_loss = 0.59578 train_acc = 0.73651 val_loss = 0.59578 val_acc = 0.74490\n",
      "1878\n",
      "1767\n",
      "2794\n",
      "3163\n",
      "591\n",
      "2401\n",
      "3021\n",
      "2650\n",
      "2488\n",
      "1823\n",
      "1819\n",
      "2815\n",
      "2326\n",
      "3480\n",
      "2339\n",
      "1377\n",
      "1578\n",
      "3312\n",
      "2263\n",
      "1021\n",
      "6514\n",
      "[Epoch 58/2000] train_loss = 0.60934 train_acc = 0.73651 val_loss = 0.60934 val_acc = 0.74489\n",
      "2263\n",
      "1767\n",
      "3163\n",
      "2326\n",
      "2401\n",
      "2650\n",
      "1578\n",
      "1021\n",
      "1878\n",
      "2488\n",
      "591\n",
      "3480\n",
      "3312\n",
      "1377\n",
      "2794\n",
      "2815\n",
      "1819\n",
      "3021\n",
      "1823\n",
      "2339\n",
      "6514\n",
      "[Epoch 59/2000] train_loss = 0.59890 train_acc = 0.73651 val_loss = 0.59890 val_acc = 0.74489\n",
      "3312\n",
      "2326\n",
      "3163\n",
      "3480\n",
      "3021\n",
      "2488\n",
      "591\n",
      "1578\n",
      "2339\n",
      "2650\n",
      "1767\n",
      "2794\n",
      "1377\n",
      "2401\n",
      "2263\n",
      "1021\n",
      "2815\n",
      "1823\n",
      "1878\n",
      "1819\n",
      "6514\n",
      "[Epoch 60/2000] train_loss = 0.60770 train_acc = 0.73651 val_loss = 0.60770 val_acc = 0.74489\n",
      "1578\n",
      "1878\n",
      "1823\n",
      "2263\n",
      "3163\n",
      "2339\n",
      "1819\n",
      "1021\n",
      "2650\n",
      "2815\n",
      "2488\n",
      "2326\n",
      "2401\n",
      "3021\n",
      "591\n",
      "2794\n",
      "3480\n",
      "1767\n",
      "3312\n",
      "1377\n",
      "6514\n",
      "[Epoch 61/2000] train_loss = 0.58525 train_acc = 0.73652 val_loss = 0.58525 val_acc = 0.74489\n",
      "3312\n",
      "3163\n",
      "1578\n",
      "2794\n",
      "1021\n",
      "1878\n",
      "2488\n",
      "2401\n",
      "2815\n",
      "2263\n",
      "1377\n",
      "3021\n",
      "1823\n",
      "3480\n",
      "2650\n",
      "591\n",
      "1819\n",
      "2339\n",
      "2326\n",
      "1767\n",
      "6514\n",
      "[Epoch 62/2000] train_loss = 0.59782 train_acc = 0.73652 val_loss = 0.59782 val_acc = 0.74489\n",
      "2488\n",
      "2339\n",
      "1377\n",
      "1021\n",
      "3163\n",
      "3312\n",
      "2815\n",
      "2650\n",
      "2794\n",
      "2326\n",
      "1819\n",
      "3021\n",
      "2401\n",
      "2263\n",
      "3480\n",
      "1767\n",
      "1878\n",
      "1823\n",
      "1578\n",
      "591\n",
      "6514\n",
      "[Epoch 63/2000] train_loss = 0.58641 train_acc = 0.73653 val_loss = 0.58641 val_acc = 0.74490\n",
      "1578\n",
      "3021\n",
      "2401\n",
      "2815\n",
      "2339\n",
      "2326\n",
      "591\n",
      "2650\n",
      "1377\n",
      "1021\n",
      "3480\n",
      "2794\n",
      "2488\n",
      "1767\n",
      "2263\n",
      "1823\n",
      "3312\n",
      "3163\n",
      "1878\n",
      "1819\n",
      "6514\n",
      "[Epoch 64/2000] train_loss = 0.58526 train_acc = 0.73652 val_loss = 0.58526 val_acc = 0.74490\n",
      "1377\n",
      "1578\n",
      "2339\n",
      "2488\n",
      "1767\n",
      "1819\n",
      "2650\n",
      "2263\n",
      "3021\n",
      "1021\n",
      "2815\n",
      "1878\n",
      "3480\n",
      "591\n",
      "1823\n",
      "3163\n",
      "3312\n",
      "2794\n",
      "2326\n",
      "2401\n",
      "6514\n",
      "[Epoch 65/2000] train_loss = 0.58183 train_acc = 0.73653 val_loss = 0.58183 val_acc = 0.74490\n",
      "3163\n",
      "591\n",
      "1823\n",
      "1767\n",
      "1819\n",
      "3480\n",
      "2815\n",
      "1377\n",
      "1578\n",
      "2488\n",
      "2263\n",
      "1021\n",
      "2339\n",
      "3021\n",
      "2794\n",
      "2650\n",
      "2326\n",
      "2401\n",
      "1878\n",
      "3312\n",
      "6514\n",
      "[Epoch 66/2000] train_loss = 0.58399 train_acc = 0.73654 val_loss = 0.58399 val_acc = 0.74491\n",
      "2815\n",
      "2263\n",
      "3480\n",
      "3312\n",
      "2650\n",
      "1767\n",
      "2794\n",
      "3021\n",
      "1578\n",
      "2339\n",
      "591\n",
      "1823\n",
      "3163\n",
      "2326\n",
      "1377\n",
      "1819\n",
      "2401\n",
      "2488\n",
      "1878\n",
      "1021\n",
      "6514\n",
      "[Epoch 67/2000] train_loss = 0.58807 train_acc = 0.73654 val_loss = 0.58807 val_acc = 0.74491\n",
      "1878\n",
      "2401\n",
      "2650\n",
      "591\n",
      "1021\n",
      "3312\n",
      "1823\n",
      "3021\n",
      "2326\n",
      "2488\n",
      "1377\n",
      "1578\n",
      "2794\n",
      "1819\n",
      "2815\n",
      "2263\n",
      "2339\n",
      "3163\n",
      "1767\n",
      "3480\n",
      "6514\n",
      "[Epoch 68/2000] train_loss = 0.58550 train_acc = 0.73654 val_loss = 0.58550 val_acc = 0.74492\n",
      "2488\n",
      "2815\n",
      "1578\n",
      "2401\n",
      "2326\n",
      "1021\n",
      "3480\n",
      "1767\n",
      "1878\n",
      "3312\n",
      "2794\n",
      "1819\n",
      "591\n",
      "2339\n",
      "1823\n",
      "2263\n",
      "3021\n",
      "3163\n",
      "2650\n",
      "1377\n",
      "6514\n",
      "[Epoch 69/2000] train_loss = 0.58999 train_acc = 0.73655 val_loss = 0.58999 val_acc = 0.74492\n",
      "2650\n",
      "2263\n",
      "1823\n",
      "2794\n",
      "591\n",
      "2401\n",
      "1578\n",
      "2326\n",
      "3163\n",
      "2815\n",
      "1377\n",
      "2339\n",
      "3480\n",
      "3021\n",
      "1021\n",
      "3312\n",
      "1767\n",
      "1878\n",
      "1819\n",
      "2488\n",
      "6514\n",
      "[Epoch 70/2000] train_loss = 0.63316 train_acc = 0.73655 val_loss = 0.63316 val_acc = 0.74494\n",
      "2488\n",
      "3480\n",
      "2815\n",
      "591\n",
      "2326\n",
      "2339\n",
      "1767\n",
      "1823\n",
      "1578\n",
      "2794\n",
      "2650\n",
      "3312\n",
      "1021\n",
      "1819\n",
      "1377\n",
      "3021\n",
      "2401\n",
      "2263\n",
      "3163\n",
      "1878\n",
      "6514\n",
      "[Epoch 71/2000] train_loss = 0.57877 train_acc = 0.73655 val_loss = 0.57877 val_acc = 0.74492\n",
      "1823\n",
      "2339\n",
      "3021\n",
      "1377\n",
      "3312\n",
      "2650\n",
      "1021\n",
      "3480\n",
      "2263\n",
      "3163\n",
      "1578\n",
      "2794\n",
      "2815\n",
      "2326\n",
      "591\n",
      "1878\n",
      "1819\n",
      "2401\n",
      "2488\n",
      "1767\n",
      "6514\n",
      "[Epoch 72/2000] train_loss = 0.58123 train_acc = 0.73655 val_loss = 0.58123 val_acc = 0.74493\n",
      "2650\n",
      "1819\n",
      "3021\n",
      "3312\n",
      "2263\n",
      "1377\n",
      "591\n",
      "1578\n",
      "1878\n",
      "1767\n",
      "2815\n",
      "2339\n",
      "1823\n",
      "1021\n",
      "2794\n",
      "3480\n",
      "2326\n",
      "2401\n",
      "3163\n",
      "2488\n",
      "6514\n",
      "[Epoch 73/2000] train_loss = 0.58048 train_acc = 0.73655 val_loss = 0.58048 val_acc = 0.74493\n",
      "1878\n",
      "2488\n",
      "3312\n",
      "1823\n",
      "1578\n",
      "1377\n",
      "2263\n",
      "2326\n",
      "3021\n",
      "591\n",
      "2794\n",
      "2815\n",
      "1767\n",
      "3163\n",
      "1021\n",
      "3480\n",
      "2339\n",
      "1819\n",
      "2401\n",
      "2650\n",
      "6514\n",
      "[Epoch 74/2000] train_loss = 0.58492 train_acc = 0.73655 val_loss = 0.58492 val_acc = 0.74495\n",
      "1021\n",
      "2401\n",
      "2815\n",
      "3021\n",
      "2488\n",
      "1819\n",
      "3163\n",
      "2794\n",
      "1578\n",
      "2326\n",
      "2263\n",
      "1823\n",
      "1767\n",
      "1377\n",
      "591\n",
      "2650\n",
      "3312\n",
      "2339\n",
      "3480\n",
      "1878\n",
      "6514\n",
      "[Epoch 75/2000] train_loss = 0.58456 train_acc = 0.73655 val_loss = 0.58456 val_acc = 0.74493\n",
      "1823\n",
      "1377\n",
      "2401\n",
      "2650\n",
      "2263\n",
      "3163\n",
      "2326\n",
      "1578\n",
      "3312\n",
      "2794\n",
      "3480\n",
      "591\n",
      "1819\n",
      "2488\n",
      "2815\n",
      "1021\n",
      "1878\n",
      "2339\n",
      "3021\n",
      "1767\n",
      "6514\n",
      "[Epoch 76/2000] train_loss = 0.57932 train_acc = 0.73656 val_loss = 0.57932 val_acc = 0.74496\n",
      "1823\n",
      "2488\n",
      "2326\n",
      "2794\n",
      "591\n",
      "2263\n",
      "3021\n",
      "3312\n",
      "1377\n",
      "2401\n",
      "1021\n",
      "3163\n",
      "2815\n",
      "3480\n",
      "2339\n",
      "1767\n",
      "2650\n",
      "1878\n",
      "1819\n",
      "1578\n",
      "6514\n",
      "[Epoch 77/2000] train_loss = 0.57599 train_acc = 0.73659 val_loss = 0.57599 val_acc = 0.74501\n",
      "3021\n",
      "2650\n",
      "1823\n",
      "3163\n",
      "3480\n",
      "1767\n",
      "591\n",
      "1578\n",
      "2339\n",
      "2263\n",
      "1021\n",
      "2488\n",
      "1377\n",
      "1819\n",
      "3312\n",
      "2401\n",
      "2794\n",
      "1878\n",
      "2326\n",
      "2815\n",
      "6514\n",
      "[Epoch 78/2000] train_loss = 0.57861 train_acc = 0.73660 val_loss = 0.57861 val_acc = 0.74502\n",
      "2339\n",
      "591\n",
      "2650\n",
      "1021\n",
      "2401\n",
      "1767\n",
      "1377\n",
      "3480\n",
      "3163\n",
      "2794\n",
      "2488\n",
      "1578\n",
      "2326\n",
      "1823\n",
      "1819\n",
      "3312\n",
      "1878\n",
      "2815\n",
      "2263\n",
      "3021\n",
      "6514\n",
      "[Epoch 79/2000] train_loss = 0.57884 train_acc = 0.73663 val_loss = 0.57884 val_acc = 0.74505\n",
      "2650\n",
      "1878\n",
      "2794\n",
      "2815\n",
      "1377\n",
      "1578\n",
      "3163\n",
      "2488\n",
      "1021\n",
      "2326\n",
      "2401\n",
      "1819\n",
      "591\n",
      "1767\n",
      "2339\n",
      "2263\n",
      "3312\n",
      "1823\n",
      "3021\n",
      "3480\n",
      "6514\n",
      "[Epoch 80/2000] train_loss = 0.58963 train_acc = 0.73659 val_loss = 0.58963 val_acc = 0.74500\n",
      "2794\n",
      "1878\n",
      "3480\n",
      "1823\n",
      "3312\n",
      "1767\n",
      "2488\n",
      "2401\n",
      "1578\n",
      "2326\n",
      "2815\n",
      "2650\n",
      "1819\n",
      "2339\n",
      "2263\n",
      "3163\n",
      "1377\n",
      "1021\n",
      "3021\n",
      "591\n",
      "6514\n",
      "[Epoch 81/2000] train_loss = 0.59037 train_acc = 0.73659 val_loss = 0.59037 val_acc = 0.74500\n",
      "1767\n",
      "2263\n",
      "591\n",
      "3021\n",
      "1377\n",
      "1819\n",
      "3312\n",
      "2339\n",
      "2815\n",
      "2794\n",
      "2650\n",
      "1021\n",
      "1878\n",
      "2401\n",
      "2488\n",
      "1578\n",
      "2326\n",
      "1823\n",
      "3480\n",
      "3163\n",
      "6514\n",
      "[Epoch 82/2000] train_loss = 0.58558 train_acc = 0.73660 val_loss = 0.58558 val_acc = 0.74503\n",
      "1823\n",
      "2650\n",
      "1021\n",
      "3163\n",
      "3480\n",
      "1819\n",
      "591\n",
      "3312\n",
      "2815\n",
      "2339\n",
      "2263\n",
      "2326\n",
      "1377\n",
      "3021\n",
      "2794\n",
      "2401\n",
      "2488\n",
      "1878\n",
      "1578\n",
      "1767\n",
      "6514\n",
      "[Epoch 83/2000] train_loss = 0.58185 train_acc = 0.73662 val_loss = 0.58185 val_acc = 0.74506\n",
      "1819\n",
      "3480\n",
      "2815\n",
      "1578\n",
      "1823\n",
      "2401\n",
      "2326\n",
      "3163\n",
      "2794\n",
      "1878\n",
      "1021\n",
      "2488\n",
      "2339\n",
      "2650\n",
      "591\n",
      "2263\n",
      "3021\n",
      "3312\n",
      "1767\n",
      "1377\n",
      "6514\n",
      "[Epoch 84/2000] train_loss = 0.57826 train_acc = 0.73663 val_loss = 0.57826 val_acc = 0.74506\n",
      "1823\n",
      "3312\n",
      "3021\n",
      "591\n",
      "1021\n",
      "2794\n",
      "1878\n",
      "1578\n",
      "2650\n",
      "2401\n",
      "2339\n",
      "2263\n",
      "1819\n",
      "3163\n",
      "2488\n",
      "1377\n",
      "1767\n",
      "3480\n",
      "2815\n",
      "2326\n",
      "6514\n",
      "[Epoch 85/2000] train_loss = 0.57747 train_acc = 0.73665 val_loss = 0.57747 val_acc = 0.74511\n",
      "2339\n",
      "3021\n",
      "1767\n",
      "2326\n",
      "2815\n",
      "591\n",
      "3312\n",
      "3163\n",
      "2263\n",
      "1021\n",
      "1377\n",
      "2401\n",
      "1878\n",
      "1823\n",
      "1819\n",
      "2488\n",
      "1578\n",
      "3480\n",
      "2650\n",
      "2794\n",
      "6514\n",
      "[Epoch 86/2000] train_loss = 0.60074 train_acc = 0.73668 val_loss = 0.60074 val_acc = 0.74513\n",
      "591\n",
      "1578\n",
      "3021\n",
      "3480\n",
      "2339\n",
      "2488\n",
      "1767\n",
      "1823\n",
      "2794\n",
      "2326\n",
      "1819\n",
      "2263\n",
      "1021\n",
      "2650\n",
      "1377\n",
      "2401\n",
      "1878\n",
      "3163\n",
      "2815\n",
      "3312\n",
      "6514\n",
      "[Epoch 87/2000] train_loss = 0.57616 train_acc = 0.73672 val_loss = 0.57616 val_acc = 0.74518\n",
      "3312\n",
      "2263\n",
      "2339\n",
      "1878\n",
      "3163\n",
      "1021\n",
      "2488\n",
      "2815\n",
      "1819\n",
      "1823\n",
      "3480\n",
      "2401\n",
      "2794\n",
      "1578\n",
      "1767\n",
      "591\n",
      "2326\n",
      "3021\n",
      "1377\n",
      "2650\n",
      "6514\n",
      "[Epoch 88/2000] train_loss = 0.58852 train_acc = 0.73674 val_loss = 0.58852 val_acc = 0.74521\n",
      "1878\n",
      "2263\n",
      "2815\n",
      "2401\n",
      "1767\n",
      "1021\n",
      "2488\n",
      "3021\n",
      "1819\n",
      "1823\n",
      "2326\n",
      "3163\n",
      "3312\n",
      "1578\n",
      "2650\n",
      "2794\n",
      "3480\n",
      "1377\n",
      "2339\n",
      "591\n",
      "6514\n",
      "[Epoch 89/2000] train_loss = 0.59075 train_acc = 0.73677 val_loss = 0.59075 val_acc = 0.74526\n",
      "2326\n",
      "2339\n",
      "1767\n",
      "1021\n",
      "2650\n",
      "2263\n",
      "3021\n",
      "1578\n",
      "3480\n",
      "2794\n",
      "1823\n",
      "2815\n",
      "591\n",
      "3312\n",
      "1819\n",
      "1878\n",
      "3163\n",
      "2488\n",
      "2401\n",
      "1377\n",
      "6514\n",
      "[Epoch 90/2000] train_loss = 0.57653 train_acc = 0.73683 val_loss = 0.57653 val_acc = 0.74532\n",
      "2488\n",
      "2794\n",
      "3312\n",
      "2326\n",
      "2339\n",
      "591\n",
      "2401\n",
      "2650\n",
      "1819\n",
      "3021\n",
      "2815\n",
      "1878\n",
      "1823\n",
      "3480\n",
      "3163\n",
      "1578\n",
      "1767\n",
      "2263\n",
      "1021\n",
      "1377\n",
      "6514\n",
      "[Epoch 91/2000] train_loss = 0.58004 train_acc = 0.73693 val_loss = 0.58004 val_acc = 0.74548\n",
      "3480\n",
      "2401\n",
      "2326\n",
      "1377\n",
      "1819\n",
      "1578\n",
      "3021\n",
      "1767\n",
      "591\n",
      "2794\n",
      "2815\n",
      "2650\n",
      "2263\n",
      "2339\n",
      "2488\n",
      "1878\n",
      "3163\n",
      "3312\n",
      "1823\n",
      "1021\n",
      "6514\n",
      "[Epoch 92/2000] train_loss = 0.57163 train_acc = 0.73699 val_loss = 0.57163 val_acc = 0.74555\n",
      "1021\n",
      "3312\n",
      "3163\n",
      "2263\n",
      "2326\n",
      "1823\n",
      "2794\n",
      "2401\n",
      "2650\n",
      "591\n",
      "1578\n",
      "2339\n",
      "1878\n",
      "3021\n",
      "1377\n",
      "3480\n",
      "1767\n",
      "2815\n",
      "1819\n",
      "2488\n",
      "6514\n",
      "[Epoch 93/2000] train_loss = 0.57637 train_acc = 0.73713 val_loss = 0.57637 val_acc = 0.74574\n",
      "2794\n",
      "1377\n",
      "2263\n",
      "2650\n",
      "1767\n",
      "3163\n",
      "1878\n",
      "2339\n",
      "591\n",
      "3312\n",
      "1823\n",
      "2815\n",
      "2488\n",
      "3021\n",
      "2401\n",
      "1819\n",
      "3480\n",
      "1578\n",
      "2326\n",
      "1021\n",
      "6514\n",
      "[Epoch 94/2000] train_loss = 0.58696 train_acc = 0.73709 val_loss = 0.58696 val_acc = 0.74571\n",
      "3312\n",
      "2815\n",
      "2401\n",
      "1578\n",
      "1767\n",
      "1819\n",
      "2650\n",
      "2263\n",
      "2326\n",
      "3021\n",
      "591\n",
      "1377\n",
      "2339\n",
      "1823\n",
      "2488\n",
      "1021\n",
      "3163\n",
      "2794\n",
      "3480\n",
      "1878\n",
      "6514\n",
      "[Epoch 95/2000] train_loss = 0.58395 train_acc = 0.73717 val_loss = 0.58395 val_acc = 0.74581\n",
      "3312\n",
      "3021\n",
      "2263\n",
      "3480\n",
      "1021\n",
      "1819\n",
      "591\n",
      "1377\n",
      "2815\n",
      "2488\n",
      "1767\n",
      "1823\n",
      "2650\n",
      "2339\n",
      "2794\n",
      "1578\n",
      "2326\n",
      "3163\n",
      "2401\n",
      "1878\n",
      "6514\n",
      "[Epoch 96/2000] train_loss = 0.57558 train_acc = 0.73724 val_loss = 0.57558 val_acc = 0.74589\n",
      "591\n",
      "2650\n",
      "1578\n",
      "2488\n",
      "2339\n",
      "1377\n",
      "1823\n",
      "2401\n",
      "1021\n",
      "1819\n",
      "3312\n",
      "3480\n",
      "2815\n",
      "2794\n",
      "3021\n",
      "3163\n",
      "2326\n",
      "1878\n",
      "2263\n",
      "1767\n",
      "6514\n",
      "[Epoch 97/2000] train_loss = 0.58863 train_acc = 0.73728 val_loss = 0.58863 val_acc = 0.74592\n",
      "591\n",
      "1823\n",
      "2815\n",
      "1377\n",
      "2488\n",
      "2794\n",
      "2650\n",
      "1878\n",
      "2263\n",
      "3021\n",
      "2339\n",
      "2401\n",
      "1767\n",
      "2326\n",
      "3312\n",
      "1021\n",
      "1819\n",
      "3163\n",
      "1578\n",
      "3480\n",
      "6514\n",
      "[Epoch 98/2000] train_loss = 0.57410 train_acc = 0.73730 val_loss = 0.57410 val_acc = 0.74592\n",
      "1878\n",
      "2263\n",
      "2815\n",
      "1578\n",
      "2326\n",
      "1021\n",
      "1767\n",
      "1823\n",
      "1377\n",
      "3480\n",
      "591\n",
      "2401\n",
      "3163\n",
      "2488\n",
      "2794\n",
      "3021\n",
      "3312\n",
      "2339\n",
      "1819\n",
      "2650\n",
      "6514\n",
      "[Epoch 99/2000] train_loss = 0.56967 train_acc = 0.73745 val_loss = 0.56967 val_acc = 0.74611\n",
      "2488\n",
      "1823\n",
      "591\n",
      "3163\n",
      "2326\n",
      "2401\n",
      "1377\n",
      "3021\n",
      "2794\n",
      "1021\n",
      "2650\n",
      "2263\n",
      "1578\n",
      "2339\n",
      "1878\n",
      "2815\n",
      "3312\n",
      "3480\n",
      "1819\n",
      "1767\n",
      "6514\n",
      "[Epoch 100/2000] train_loss = 0.58581 train_acc = 0.73763 val_loss = 0.58581 val_acc = 0.74625\n",
      "1878\n",
      "3480\n",
      "1578\n",
      "591\n",
      "2488\n",
      "1819\n",
      "2326\n",
      "2263\n",
      "3163\n",
      "3312\n",
      "2401\n",
      "1767\n",
      "2815\n",
      "3021\n",
      "2650\n",
      "2794\n",
      "1823\n",
      "2339\n",
      "1377\n",
      "1021\n",
      "6514\n",
      "[Epoch 101/2000] train_loss = 0.58604 train_acc = 0.73764 val_loss = 0.58604 val_acc = 0.74626\n",
      "2815\n",
      "3312\n",
      "1767\n",
      "2650\n",
      "3480\n",
      "2488\n",
      "3163\n",
      "1021\n",
      "2263\n",
      "2794\n",
      "1819\n",
      "2326\n",
      "1578\n",
      "3021\n",
      "2401\n",
      "1878\n",
      "1377\n",
      "1823\n",
      "2339\n",
      "591\n",
      "6514\n",
      "[Epoch 102/2000] train_loss = 0.57324 train_acc = 0.73763 val_loss = 0.57324 val_acc = 0.74626\n",
      "2794\n",
      "2488\n",
      "1819\n",
      "1377\n",
      "2650\n",
      "1823\n",
      "2815\n",
      "1578\n",
      "3163\n",
      "3312\n",
      "2326\n",
      "3480\n",
      "1021\n",
      "2401\n",
      "2339\n",
      "1767\n",
      "3021\n",
      "1878\n",
      "591\n",
      "2263\n",
      "6514\n",
      "[Epoch 103/2000] train_loss = 0.58488 train_acc = 0.73772 val_loss = 0.58488 val_acc = 0.74638\n",
      "3021\n",
      "1021\n",
      "1767\n",
      "3312\n",
      "2339\n",
      "2401\n",
      "3163\n",
      "2263\n",
      "1823\n",
      "1578\n",
      "2650\n",
      "2326\n",
      "1819\n",
      "2488\n",
      "2815\n",
      "1878\n",
      "2794\n",
      "1377\n",
      "591\n",
      "3480\n",
      "6514\n",
      "[Epoch 104/2000] train_loss = 0.62709 train_acc = 0.73774 val_loss = 0.62709 val_acc = 0.74643\n",
      "1878\n",
      "1819\n",
      "3312\n",
      "3480\n",
      "2488\n",
      "2794\n",
      "2815\n",
      "1377\n",
      "2650\n",
      "2401\n",
      "2339\n",
      "591\n",
      "1823\n",
      "2263\n",
      "1021\n",
      "1578\n",
      "3163\n",
      "1767\n",
      "2326\n",
      "3021\n",
      "6514\n",
      "[Epoch 105/2000] train_loss = 0.57229 train_acc = 0.73776 val_loss = 0.57229 val_acc = 0.74648\n",
      "3312\n",
      "1878\n",
      "1377\n",
      "1021\n",
      "1767\n",
      "3021\n",
      "591\n",
      "2815\n",
      "2263\n",
      "2339\n",
      "3480\n",
      "2326\n",
      "2794\n",
      "3163\n",
      "1578\n",
      "1823\n",
      "2650\n",
      "2488\n",
      "1819\n",
      "2401\n",
      "6514\n",
      "[Epoch 106/2000] train_loss = 0.60153 train_acc = 0.73777 val_loss = 0.60153 val_acc = 0.74649\n",
      "2339\n",
      "1819\n",
      "2650\n",
      "3021\n",
      "3312\n",
      "1767\n",
      "2263\n",
      "2326\n",
      "3163\n",
      "1878\n",
      "2488\n",
      "2794\n",
      "1377\n",
      "1021\n",
      "1578\n",
      "3480\n",
      "2815\n",
      "1823\n",
      "591\n",
      "2401\n",
      "6514\n",
      "[Epoch 107/2000] train_loss = 0.57722 train_acc = 0.73777 val_loss = 0.57722 val_acc = 0.74648\n",
      "2339\n",
      "3021\n",
      "1823\n",
      "3163\n",
      "1878\n",
      "1377\n",
      "3312\n",
      "591\n",
      "1578\n",
      "1021\n",
      "2794\n",
      "1819\n",
      "2263\n",
      "2488\n",
      "2650\n",
      "2815\n",
      "2401\n",
      "3480\n",
      "1767\n",
      "2326\n",
      "6514\n",
      "[Epoch 108/2000] train_loss = 0.58466 train_acc = 0.73776 val_loss = 0.58466 val_acc = 0.74647\n",
      "591\n",
      "1878\n",
      "1767\n",
      "2326\n",
      "1377\n",
      "3480\n",
      "2815\n",
      "1819\n",
      "3163\n",
      "2794\n",
      "2488\n",
      "1823\n",
      "1578\n",
      "3021\n",
      "2650\n",
      "3312\n",
      "2401\n",
      "2263\n",
      "2339\n",
      "1021\n",
      "6514\n",
      "[Epoch 109/2000] train_loss = 0.59635 train_acc = 0.73774 val_loss = 0.59635 val_acc = 0.74646\n",
      "2326\n",
      "1823\n",
      "2263\n",
      "591\n",
      "1377\n",
      "2650\n",
      "3163\n",
      "3480\n",
      "1578\n",
      "2401\n",
      "2815\n",
      "2488\n",
      "1819\n",
      "3021\n",
      "2339\n",
      "1767\n",
      "3312\n",
      "1021\n",
      "1878\n",
      "2794\n",
      "6514\n",
      "[Epoch 110/2000] train_loss = 0.58138 train_acc = 0.73774 val_loss = 0.58138 val_acc = 0.74644\n",
      "1377\n",
      "2488\n",
      "1767\n",
      "1021\n",
      "1578\n",
      "3021\n",
      "2401\n",
      "591\n",
      "3312\n",
      "2794\n",
      "1819\n",
      "1823\n",
      "3163\n",
      "1878\n",
      "2650\n",
      "2815\n",
      "2263\n",
      "2326\n",
      "3480\n",
      "2339\n",
      "6514\n",
      "[Epoch 111/2000] train_loss = 0.57430 train_acc = 0.73774 val_loss = 0.57430 val_acc = 0.74644\n",
      "1819\n",
      "2650\n",
      "1578\n",
      "2488\n",
      "2815\n",
      "3163\n",
      "3021\n",
      "2401\n",
      "1767\n",
      "2794\n",
      "2339\n",
      "3312\n",
      "1823\n",
      "1021\n",
      "1878\n",
      "1377\n",
      "591\n",
      "2263\n",
      "3480\n",
      "2326\n",
      "6514\n",
      "[Epoch 112/2000] train_loss = 0.58451 train_acc = 0.73767 val_loss = 0.58451 val_acc = 0.74641\n",
      "3163\n",
      "1878\n",
      "2339\n",
      "1021\n",
      "1578\n",
      "3021\n",
      "1767\n",
      "591\n",
      "2488\n",
      "2815\n",
      "3480\n",
      "2326\n",
      "2263\n",
      "2401\n",
      "1823\n",
      "2650\n",
      "2794\n",
      "1377\n",
      "3312\n",
      "1819\n",
      "6514\n",
      "[Epoch 113/2000] train_loss = 0.56795 train_acc = 0.73767 val_loss = 0.56795 val_acc = 0.74641\n",
      "1819\n",
      "3021\n",
      "1767\n",
      "2488\n",
      "3163\n",
      "1578\n",
      "3480\n",
      "1021\n",
      "2401\n",
      "2794\n",
      "2263\n",
      "2650\n",
      "2815\n",
      "2326\n",
      "591\n",
      "1878\n",
      "1823\n",
      "1377\n",
      "2339\n",
      "3312\n",
      "6514\n",
      "[Epoch 114/2000] train_loss = 0.57240 train_acc = 0.73766 val_loss = 0.57240 val_acc = 0.74640\n",
      "2401\n",
      "2339\n",
      "3021\n",
      "2815\n",
      "1767\n",
      "2263\n",
      "2488\n",
      "1377\n",
      "1021\n",
      "2794\n",
      "1823\n",
      "3163\n",
      "3480\n",
      "2650\n",
      "1578\n",
      "591\n",
      "1878\n",
      "2326\n",
      "1819\n",
      "3312\n",
      "6514\n",
      "[Epoch 115/2000] train_loss = 0.57545 train_acc = 0.73759 val_loss = 0.57545 val_acc = 0.74635\n",
      "1878\n",
      "2488\n",
      "3480\n",
      "2401\n",
      "1021\n",
      "3312\n",
      "1767\n",
      "3163\n",
      "1823\n",
      "2326\n",
      "591\n",
      "2650\n",
      "2794\n",
      "3021\n",
      "1377\n",
      "1578\n",
      "2263\n",
      "1819\n",
      "2815\n",
      "2339\n",
      "6514\n",
      "[Epoch 116/2000] train_loss = 0.57539 train_acc = 0.73755 val_loss = 0.57539 val_acc = 0.74631\n",
      "3312\n",
      "1819\n",
      "2650\n",
      "3163\n",
      "1823\n",
      "2401\n",
      "1578\n",
      "1878\n",
      "2815\n",
      "2339\n",
      "1767\n",
      "1021\n",
      "3480\n",
      "591\n",
      "2326\n",
      "2488\n",
      "2794\n",
      "2263\n",
      "1377\n",
      "3021\n",
      "6514\n",
      "[Epoch 117/2000] train_loss = 0.57509 train_acc = 0.73754 val_loss = 0.57509 val_acc = 0.74629\n",
      "1819\n",
      "2263\n",
      "2815\n",
      "591\n",
      "2326\n",
      "1767\n",
      "2650\n",
      "2339\n",
      "2401\n",
      "1578\n",
      "1878\n",
      "1823\n",
      "3021\n",
      "1021\n",
      "2488\n",
      "3312\n",
      "3480\n",
      "3163\n",
      "1377\n",
      "2794\n",
      "6514\n",
      "[Epoch 118/2000] train_loss = 0.60000 train_acc = 0.73745 val_loss = 0.60000 val_acc = 0.74624\n",
      "2339\n",
      "3480\n",
      "2263\n",
      "2401\n",
      "2488\n",
      "1823\n",
      "2815\n",
      "3021\n",
      "1878\n",
      "3312\n",
      "1578\n",
      "3163\n",
      "2326\n",
      "2650\n",
      "1767\n",
      "1819\n",
      "1021\n",
      "591\n",
      "2794\n",
      "1377\n",
      "6514\n",
      "[Epoch 119/2000] train_loss = 0.59515 train_acc = 0.73741 val_loss = 0.59515 val_acc = 0.74621\n",
      "1578\n",
      "2326\n",
      "2263\n",
      "2339\n",
      "1377\n",
      "3480\n",
      "1767\n",
      "2488\n",
      "591\n",
      "3021\n",
      "2815\n",
      "3312\n",
      "1878\n",
      "3163\n",
      "2794\n",
      "1823\n",
      "2650\n",
      "1819\n",
      "1021\n",
      "2401\n",
      "6514\n",
      "[Epoch 120/2000] train_loss = 0.57110 train_acc = 0.73750 val_loss = 0.57110 val_acc = 0.74627\n",
      "1767\n",
      "591\n",
      "2488\n",
      "1021\n",
      "3312\n",
      "3163\n",
      "2815\n",
      "3021\n",
      "2326\n",
      "2263\n",
      "1377\n",
      "1823\n",
      "1578\n",
      "3480\n",
      "1878\n",
      "2650\n",
      "2401\n",
      "2339\n",
      "1819\n",
      "2794\n",
      "6514\n",
      "[Epoch 121/2000] train_loss = 0.57966 train_acc = 0.73741 val_loss = 0.57966 val_acc = 0.74621\n",
      "3021\n",
      "2794\n",
      "2650\n",
      "2401\n",
      "2815\n",
      "2263\n",
      "3163\n",
      "1823\n",
      "591\n",
      "1578\n",
      "3312\n",
      "2488\n",
      "2326\n",
      "1767\n",
      "1878\n",
      "1377\n",
      "1819\n",
      "1021\n",
      "2339\n",
      "3480\n",
      "6514\n",
      "[Epoch 122/2000] train_loss = 0.57022 train_acc = 0.73742 val_loss = 0.57022 val_acc = 0.74621\n",
      "2326\n",
      "3480\n",
      "3312\n",
      "2794\n",
      "1377\n",
      "591\n",
      "2401\n",
      "2263\n",
      "3163\n",
      "2339\n",
      "1021\n",
      "2815\n",
      "1878\n",
      "2488\n",
      "2650\n",
      "3021\n",
      "1823\n",
      "1578\n",
      "1767\n",
      "1819\n",
      "6514\n",
      "[Epoch 123/2000] train_loss = 0.56919 train_acc = 0.73734 val_loss = 0.56919 val_acc = 0.74619\n",
      "2339\n",
      "3480\n",
      "1878\n",
      "1819\n",
      "2401\n",
      "1377\n",
      "2488\n",
      "2650\n",
      "1021\n",
      "1823\n",
      "1578\n",
      "591\n",
      "2794\n",
      "2263\n",
      "3163\n",
      "3021\n",
      "2815\n",
      "3312\n",
      "2326\n",
      "1767\n",
      "6514\n",
      "[Epoch 124/2000] train_loss = 0.56538 train_acc = 0.73734 val_loss = 0.56538 val_acc = 0.74617\n",
      "2488\n",
      "2794\n",
      "3480\n",
      "2339\n",
      "1767\n",
      "1377\n",
      "3021\n",
      "3312\n",
      "2263\n",
      "1878\n",
      "2650\n",
      "2815\n",
      "2326\n",
      "1819\n",
      "1021\n",
      "2401\n",
      "3163\n",
      "1823\n",
      "591\n",
      "1578\n",
      "6514\n",
      "[Epoch 125/2000] train_loss = 0.57097 train_acc = 0.73735 val_loss = 0.57097 val_acc = 0.74619\n",
      "2794\n",
      "591\n",
      "3480\n",
      "1819\n",
      "2263\n",
      "3312\n",
      "2326\n",
      "2650\n",
      "1377\n",
      "1578\n",
      "2401\n",
      "1767\n",
      "3021\n",
      "2488\n",
      "3163\n",
      "1021\n",
      "2339\n",
      "1878\n",
      "1823\n",
      "2815\n",
      "6514\n",
      "[Epoch 126/2000] train_loss = 0.56986 train_acc = 0.73729 val_loss = 0.56986 val_acc = 0.74613\n",
      "1021\n",
      "3480\n",
      "2815\n",
      "2263\n",
      "1819\n",
      "1578\n",
      "1377\n",
      "3312\n",
      "3021\n",
      "2794\n",
      "591\n",
      "2326\n",
      "3163\n",
      "1767\n",
      "2650\n",
      "2339\n",
      "2401\n",
      "2488\n",
      "1823\n",
      "1878\n",
      "6514\n",
      "[Epoch 127/2000] train_loss = 0.56903 train_acc = 0.73729 val_loss = 0.56903 val_acc = 0.74614\n",
      "2401\n",
      "1021\n",
      "2326\n",
      "2794\n",
      "1578\n",
      "1819\n",
      "1823\n",
      "591\n",
      "2650\n",
      "2815\n",
      "2488\n",
      "1767\n",
      "2263\n",
      "2339\n",
      "3312\n",
      "1377\n",
      "3163\n",
      "3021\n",
      "3480\n",
      "1878\n",
      "6514\n",
      "[Epoch 128/2000] train_loss = 0.56860 train_acc = 0.73729 val_loss = 0.56860 val_acc = 0.74614\n",
      "2650\n",
      "3312\n",
      "1819\n",
      "3480\n",
      "1878\n",
      "1578\n",
      "2339\n",
      "2401\n",
      "3163\n",
      "1823\n",
      "2794\n",
      "2326\n",
      "591\n",
      "1377\n",
      "2815\n",
      "2488\n",
      "2263\n",
      "3021\n",
      "1767\n",
      "1021\n",
      "6514\n",
      "[Epoch 129/2000] train_loss = 0.56870 train_acc = 0.73726 val_loss = 0.56870 val_acc = 0.74612\n",
      "2650\n",
      "2794\n",
      "1578\n",
      "2401\n",
      "1819\n",
      "3480\n",
      "591\n",
      "2339\n",
      "3312\n",
      "1823\n",
      "2488\n",
      "2815\n",
      "1767\n",
      "1377\n",
      "1021\n",
      "1878\n",
      "3163\n",
      "2326\n",
      "2263\n",
      "3021\n",
      "6514\n",
      "[Epoch 130/2000] train_loss = 0.58098 train_acc = 0.73725 val_loss = 0.58098 val_acc = 0.74611\n",
      "1823\n",
      "2650\n",
      "3163\n",
      "1021\n",
      "2488\n",
      "1377\n",
      "2263\n",
      "1578\n",
      "3312\n",
      "591\n",
      "3021\n",
      "2326\n",
      "3480\n",
      "2794\n",
      "1878\n",
      "1819\n",
      "1767\n",
      "2339\n",
      "2815\n",
      "2401\n",
      "6514\n",
      "[Epoch 131/2000] train_loss = 0.56942 train_acc = 0.73724 val_loss = 0.56942 val_acc = 0.74611\n",
      "1819\n",
      "1823\n",
      "1578\n",
      "2794\n",
      "2263\n",
      "1377\n",
      "2401\n",
      "3480\n",
      "1878\n",
      "2650\n",
      "2488\n",
      "3163\n",
      "1767\n",
      "2326\n",
      "2339\n",
      "3021\n",
      "1021\n",
      "2815\n",
      "591\n",
      "3312\n",
      "6514\n",
      "[Epoch 132/2000] train_loss = 0.58073 train_acc = 0.73723 val_loss = 0.58073 val_acc = 0.74610\n",
      "1767\n",
      "591\n",
      "2326\n",
      "1377\n",
      "2650\n",
      "2794\n",
      "3021\n",
      "1021\n",
      "2488\n",
      "2401\n",
      "1578\n",
      "2263\n",
      "1819\n",
      "1823\n",
      "3480\n",
      "3163\n",
      "2815\n",
      "3312\n",
      "2339\n",
      "1878\n",
      "6514\n",
      "[Epoch 133/2000] train_loss = 0.56757 train_acc = 0.73724 val_loss = 0.56757 val_acc = 0.74611\n",
      "2326\n",
      "1878\n",
      "3021\n",
      "2401\n",
      "2650\n",
      "1819\n",
      "2339\n",
      "2794\n",
      "1767\n",
      "591\n",
      "3312\n",
      "3163\n",
      "2488\n",
      "3480\n",
      "1021\n",
      "1823\n",
      "2815\n",
      "1377\n",
      "1578\n",
      "2263\n",
      "6514\n",
      "[Epoch 134/2000] train_loss = 0.57048 train_acc = 0.73724 val_loss = 0.57048 val_acc = 0.74611\n",
      "1578\n",
      "591\n",
      "1823\n",
      "2815\n",
      "2326\n",
      "2401\n",
      "3480\n",
      "3312\n",
      "1878\n",
      "2488\n",
      "2794\n",
      "2650\n",
      "2339\n",
      "1767\n",
      "2263\n",
      "1021\n",
      "3021\n",
      "1377\n",
      "1819\n",
      "3163\n",
      "6514\n",
      "[Epoch 135/2000] train_loss = 0.57003 train_acc = 0.73723 val_loss = 0.57003 val_acc = 0.74612\n",
      "1823\n",
      "3480\n",
      "1021\n",
      "2650\n",
      "1878\n",
      "3163\n",
      "2339\n",
      "2401\n",
      "3021\n",
      "2488\n",
      "2815\n",
      "1819\n",
      "2263\n",
      "1767\n",
      "2326\n",
      "1578\n",
      "1377\n",
      "3312\n",
      "591\n",
      "2794\n",
      "6514\n",
      "[Epoch 136/2000] train_loss = 0.57968 train_acc = 0.73723 val_loss = 0.57968 val_acc = 0.74610\n",
      "2401\n",
      "3163\n",
      "1819\n",
      "2815\n",
      "2488\n",
      "1878\n",
      "3480\n",
      "1823\n",
      "3312\n",
      "2650\n",
      "1021\n",
      "1578\n",
      "591\n",
      "1767\n",
      "2326\n",
      "3021\n",
      "1377\n",
      "2794\n",
      "2263\n",
      "2339\n",
      "6514\n",
      "[Epoch 137/2000] train_loss = 0.56903 train_acc = 0.73724 val_loss = 0.56903 val_acc = 0.74612\n",
      "1377\n",
      "2401\n",
      "591\n",
      "2488\n",
      "2650\n",
      "1021\n",
      "2794\n",
      "1578\n",
      "1767\n",
      "1878\n",
      "2263\n",
      "3163\n",
      "3480\n",
      "3312\n",
      "1819\n",
      "2326\n",
      "2815\n",
      "1823\n",
      "3021\n",
      "2339\n",
      "6514\n",
      "[Epoch 138/2000] train_loss = 0.59281 train_acc = 0.73724 val_loss = 0.59281 val_acc = 0.74612\n",
      "3480\n",
      "1878\n",
      "1578\n",
      "591\n",
      "1767\n",
      "1377\n",
      "2339\n",
      "1819\n",
      "3021\n",
      "2326\n",
      "2815\n",
      "2401\n",
      "2488\n",
      "1021\n",
      "2650\n",
      "1823\n",
      "3163\n",
      "2794\n",
      "2263\n",
      "3312\n",
      "6514\n",
      "[Epoch 139/2000] train_loss = 0.59703 train_acc = 0.73723 val_loss = 0.59703 val_acc = 0.74611\n",
      "591\n",
      "1377\n",
      "2794\n",
      "2326\n",
      "2401\n",
      "2650\n",
      "1578\n",
      "3480\n",
      "3312\n",
      "1819\n",
      "2263\n",
      "2815\n",
      "2339\n",
      "1021\n",
      "1767\n",
      "1823\n",
      "1878\n",
      "3021\n",
      "2488\n",
      "3163\n",
      "6514\n",
      "[Epoch 140/2000] train_loss = 0.57457 train_acc = 0.73724 val_loss = 0.57457 val_acc = 0.74612\n",
      "2650\n",
      "3163\n",
      "1021\n",
      "2339\n",
      "2401\n",
      "2263\n",
      "2794\n",
      "3480\n",
      "1767\n",
      "2488\n",
      "2815\n",
      "1878\n",
      "3312\n",
      "3021\n",
      "1377\n",
      "1819\n",
      "591\n",
      "1578\n",
      "1823\n",
      "2326\n",
      "6514\n",
      "[Epoch 141/2000] train_loss = 0.56850 train_acc = 0.73724 val_loss = 0.56850 val_acc = 0.74612\n",
      "2339\n",
      "3480\n",
      "1823\n",
      "1578\n",
      "2815\n",
      "2488\n",
      "2326\n",
      "2794\n",
      "1878\n",
      "2401\n",
      "3163\n",
      "2650\n",
      "1767\n",
      "591\n",
      "2263\n",
      "1377\n",
      "3021\n",
      "3312\n",
      "1021\n",
      "1819\n",
      "6514\n",
      "[Epoch 142/2000] train_loss = 0.57094 train_acc = 0.73723 val_loss = 0.57094 val_acc = 0.74611\n",
      "1823\n",
      "2488\n",
      "2650\n",
      "1021\n",
      "2401\n",
      "1578\n",
      "2815\n",
      "2263\n",
      "1878\n",
      "2326\n",
      "2794\n",
      "3480\n",
      "1767\n",
      "3021\n",
      "3163\n",
      "1819\n",
      "3312\n",
      "2339\n",
      "1377\n",
      "591\n",
      "6514\n",
      "[Epoch 143/2000] train_loss = 0.59109 train_acc = 0.73723 val_loss = 0.59109 val_acc = 0.74611\n",
      "2650\n",
      "1578\n",
      "1823\n",
      "3163\n",
      "2401\n",
      "1767\n",
      "1021\n",
      "2326\n",
      "591\n",
      "1819\n",
      "3480\n",
      "2794\n",
      "2339\n",
      "3021\n",
      "2488\n",
      "2815\n",
      "3312\n",
      "1878\n",
      "2263\n",
      "1377\n",
      "6514\n",
      "[Epoch 144/2000] train_loss = 0.56840 train_acc = 0.73723 val_loss = 0.56840 val_acc = 0.74611\n",
      "2401\n",
      "591\n",
      "3312\n",
      "2794\n",
      "1377\n",
      "3021\n",
      "1823\n",
      "2339\n",
      "1021\n",
      "2488\n",
      "2650\n",
      "3480\n",
      "1767\n",
      "1578\n",
      "2815\n",
      "1878\n",
      "2326\n",
      "3163\n",
      "1819\n",
      "2263\n",
      "6514\n",
      "[Epoch 145/2000] train_loss = 0.56773 train_acc = 0.73723 val_loss = 0.56773 val_acc = 0.74611\n",
      "3163\n",
      "2488\n",
      "1767\n",
      "2401\n",
      "1819\n",
      "1878\n",
      "591\n",
      "2794\n",
      "1578\n",
      "3021\n",
      "2263\n",
      "1823\n",
      "2326\n",
      "3312\n",
      "1377\n",
      "2815\n",
      "3480\n",
      "2339\n",
      "2650\n",
      "1021\n",
      "6514\n",
      "[Epoch 146/2000] train_loss = 0.57498 train_acc = 0.73724 val_loss = 0.57498 val_acc = 0.74612\n",
      "2401\n",
      "1578\n",
      "1767\n",
      "3021\n",
      "2326\n",
      "2339\n",
      "3163\n",
      "1377\n",
      "1819\n",
      "2794\n",
      "2815\n",
      "1823\n",
      "1021\n",
      "2488\n",
      "1878\n",
      "2263\n",
      "591\n",
      "3312\n",
      "2650\n",
      "3480\n",
      "6514\n",
      "[Epoch 147/2000] train_loss = 0.57560 train_acc = 0.73722 val_loss = 0.57560 val_acc = 0.74610\n",
      "1819\n",
      "2488\n",
      "591\n",
      "1767\n",
      "3163\n",
      "1578\n",
      "3480\n",
      "3312\n",
      "1878\n",
      "2650\n",
      "1823\n",
      "1021\n",
      "2263\n",
      "3021\n",
      "2815\n",
      "1377\n",
      "2794\n",
      "2339\n",
      "2326\n",
      "2401\n",
      "6514\n",
      "[Epoch 148/2000] train_loss = 0.57001 train_acc = 0.73723 val_loss = 0.57001 val_acc = 0.74612\n",
      "1578\n",
      "3480\n",
      "1377\n",
      "2263\n",
      "2401\n",
      "1767\n",
      "1819\n",
      "2815\n",
      "1823\n",
      "2339\n",
      "2326\n",
      "591\n",
      "2650\n",
      "2488\n",
      "3021\n",
      "2794\n",
      "1878\n",
      "3163\n",
      "1021\n",
      "3312\n",
      "6514\n",
      "[Epoch 149/2000] train_loss = 0.56971 train_acc = 0.73723 val_loss = 0.56971 val_acc = 0.74612\n",
      "2263\n",
      "2339\n",
      "3021\n",
      "2326\n",
      "2488\n",
      "1767\n",
      "1819\n",
      "1878\n",
      "1823\n",
      "3312\n",
      "591\n",
      "3163\n",
      "2815\n",
      "2794\n",
      "1021\n",
      "3480\n",
      "1578\n",
      "2650\n",
      "2401\n",
      "1377\n",
      "6514\n",
      "[Epoch 150/2000] train_loss = 0.56164 train_acc = 0.73724 val_loss = 0.56164 val_acc = 0.74612\n",
      "1578\n",
      "1819\n",
      "1878\n",
      "3312\n",
      "2650\n",
      "3021\n",
      "2263\n",
      "1767\n",
      "1377\n",
      "3163\n",
      "2339\n",
      "1823\n",
      "2488\n",
      "1021\n",
      "2794\n",
      "3480\n",
      "2326\n",
      "2815\n",
      "591\n",
      "2401\n",
      "6514\n",
      "[Epoch 151/2000] train_loss = 0.56678 train_acc = 0.73724 val_loss = 0.56678 val_acc = 0.74613\n",
      "591\n",
      "2326\n",
      "1767\n",
      "3163\n",
      "2650\n",
      "3021\n",
      "2488\n",
      "1878\n",
      "3480\n",
      "1823\n",
      "2339\n",
      "2794\n",
      "1819\n",
      "3312\n",
      "1578\n",
      "1377\n",
      "2263\n",
      "2815\n",
      "2401\n",
      "1021\n",
      "6514\n",
      "[Epoch 152/2000] train_loss = 0.57725 train_acc = 0.73724 val_loss = 0.57725 val_acc = 0.74612\n",
      "2650\n",
      "3021\n",
      "1767\n",
      "2263\n",
      "1377\n",
      "591\n",
      "3480\n",
      "2815\n",
      "2794\n",
      "1823\n",
      "2326\n",
      "1578\n",
      "1021\n",
      "1878\n",
      "1819\n",
      "3312\n",
      "2339\n",
      "2488\n",
      "2401\n",
      "3163\n",
      "6514\n",
      "[Epoch 153/2000] train_loss = 0.56516 train_acc = 0.73724 val_loss = 0.56516 val_acc = 0.74612\n",
      "2650\n",
      "1823\n",
      "2263\n",
      "2815\n",
      "1578\n",
      "1021\n",
      "3312\n",
      "3163\n",
      "2488\n",
      "1767\n",
      "1878\n",
      "591\n",
      "2339\n",
      "3021\n",
      "2794\n",
      "1819\n",
      "3480\n",
      "2326\n",
      "1377\n",
      "2401\n",
      "6514\n",
      "[Epoch 154/2000] train_loss = 0.56942 train_acc = 0.73724 val_loss = 0.56942 val_acc = 0.74613\n",
      "2488\n",
      "2815\n",
      "591\n",
      "3021\n",
      "3312\n",
      "1578\n",
      "1767\n",
      "2650\n",
      "3480\n",
      "2263\n",
      "3163\n",
      "2339\n",
      "1021\n",
      "2794\n",
      "1819\n",
      "2326\n",
      "1878\n",
      "2401\n",
      "1823\n",
      "1377\n",
      "6514\n",
      "[Epoch 155/2000] train_loss = 0.61808 train_acc = 0.73724 val_loss = 0.61808 val_acc = 0.74613\n",
      "2488\n",
      "1377\n",
      "1767\n",
      "3480\n",
      "591\n",
      "3163\n",
      "1021\n",
      "2326\n",
      "2339\n",
      "2650\n",
      "1823\n",
      "2815\n",
      "3021\n",
      "2401\n",
      "1819\n",
      "2794\n",
      "3312\n",
      "1578\n",
      "1878\n",
      "2263\n",
      "6514\n",
      "[Epoch 156/2000] train_loss = 0.56530 train_acc = 0.73724 val_loss = 0.56530 val_acc = 0.74612\n",
      "2326\n",
      "2650\n",
      "3480\n",
      "1819\n",
      "2815\n",
      "1823\n",
      "3021\n",
      "3312\n",
      "2339\n",
      "1767\n",
      "591\n",
      "1377\n",
      "1021\n",
      "1578\n",
      "2401\n",
      "3163\n",
      "2488\n",
      "2263\n",
      "2794\n",
      "1878\n",
      "6514\n",
      "[Epoch 157/2000] train_loss = 0.57219 train_acc = 0.73724 val_loss = 0.57219 val_acc = 0.74613\n",
      "2401\n",
      "3312\n",
      "1021\n",
      "2326\n",
      "2815\n",
      "3021\n",
      "2488\n",
      "1767\n",
      "2650\n",
      "2263\n",
      "1878\n",
      "1823\n",
      "1578\n",
      "1377\n",
      "2794\n",
      "3480\n",
      "591\n",
      "2339\n",
      "3163\n",
      "1819\n",
      "6514\n",
      "[Epoch 158/2000] train_loss = 0.57210 train_acc = 0.73724 val_loss = 0.57210 val_acc = 0.74612\n",
      "2794\n",
      "2339\n",
      "3480\n",
      "2326\n",
      "2263\n",
      "591\n",
      "3312\n",
      "2815\n",
      "2488\n",
      "1578\n",
      "1878\n",
      "1767\n",
      "1823\n",
      "1377\n",
      "2401\n",
      "3163\n",
      "1021\n",
      "1819\n",
      "3021\n",
      "2650\n",
      "6514\n",
      "[Epoch 159/2000] train_loss = 0.55952 train_acc = 0.73723 val_loss = 0.55952 val_acc = 0.74612\n",
      "1823\n",
      "591\n",
      "1878\n",
      "1377\n",
      "2488\n",
      "2326\n",
      "1021\n",
      "2263\n",
      "1578\n",
      "2650\n",
      "2815\n",
      "3480\n",
      "3312\n",
      "2794\n",
      "2401\n",
      "3021\n",
      "3163\n",
      "1819\n",
      "1767\n",
      "2339\n",
      "6514\n",
      "[Epoch 160/2000] train_loss = 0.56471 train_acc = 0.73724 val_loss = 0.56471 val_acc = 0.74612\n",
      "1377\n",
      "2815\n",
      "2339\n",
      "3480\n",
      "1819\n",
      "591\n",
      "3163\n",
      "2401\n",
      "2650\n",
      "2326\n",
      "1767\n",
      "2794\n",
      "1823\n",
      "3312\n",
      "1578\n",
      "2488\n",
      "2263\n",
      "1021\n",
      "3021\n",
      "1878\n",
      "6514\n",
      "[Epoch 161/2000] train_loss = 0.56444 train_acc = 0.73724 val_loss = 0.56444 val_acc = 0.74611\n",
      "2488\n",
      "2339\n",
      "2326\n",
      "2815\n",
      "1819\n",
      "3021\n",
      "1767\n",
      "2650\n",
      "1578\n",
      "2263\n",
      "3480\n",
      "591\n",
      "1878\n",
      "1823\n",
      "1377\n",
      "3312\n",
      "2794\n",
      "1021\n",
      "2401\n",
      "3163\n",
      "6514\n",
      "[Epoch 162/2000] train_loss = 0.56568 train_acc = 0.73724 val_loss = 0.56568 val_acc = 0.74612\n",
      "1578\n",
      "3163\n",
      "2263\n",
      "2326\n",
      "1823\n",
      "591\n",
      "3480\n",
      "2339\n",
      "1767\n",
      "1377\n",
      "2815\n",
      "2650\n",
      "2794\n",
      "3312\n",
      "1819\n",
      "2401\n",
      "1021\n",
      "2488\n",
      "3021\n",
      "1878\n",
      "6514\n",
      "[Epoch 163/2000] train_loss = 0.56335 train_acc = 0.73725 val_loss = 0.56335 val_acc = 0.74612\n",
      "2794\n",
      "1377\n",
      "2815\n",
      "591\n",
      "1578\n",
      "1767\n",
      "2401\n",
      "1819\n",
      "2263\n",
      "3312\n",
      "1878\n",
      "2650\n",
      "2339\n",
      "2326\n",
      "3021\n",
      "1823\n",
      "3163\n",
      "3480\n",
      "2488\n",
      "1021\n",
      "6514\n",
      "[Epoch 164/2000] train_loss = 0.57314 train_acc = 0.73724 val_loss = 0.57314 val_acc = 0.74611\n",
      "3312\n",
      "2794\n",
      "1021\n",
      "1578\n",
      "3480\n",
      "1767\n",
      "1878\n",
      "591\n",
      "2488\n",
      "2339\n",
      "3021\n",
      "2650\n",
      "1823\n",
      "2815\n",
      "2326\n",
      "2263\n",
      "2401\n",
      "1819\n",
      "3163\n",
      "1377\n",
      "6514\n",
      "[Epoch 165/2000] train_loss = 0.57080 train_acc = 0.73724 val_loss = 0.57080 val_acc = 0.74612\n",
      "2650\n",
      "3021\n",
      "3312\n",
      "591\n",
      "1021\n",
      "3480\n",
      "2326\n",
      "1377\n",
      "2401\n",
      "1878\n",
      "2488\n",
      "3163\n",
      "2339\n",
      "1578\n",
      "1823\n",
      "2263\n",
      "2794\n",
      "1767\n",
      "1819\n",
      "2815\n",
      "6514\n",
      "[Epoch 166/2000] train_loss = 0.58812 train_acc = 0.73725 val_loss = 0.58812 val_acc = 0.74612\n",
      "1819\n",
      "3312\n",
      "1823\n",
      "2263\n",
      "1878\n",
      "2794\n",
      "2339\n",
      "591\n",
      "2326\n",
      "2401\n",
      "1377\n",
      "1578\n",
      "1021\n",
      "3163\n",
      "1767\n",
      "2815\n",
      "3021\n",
      "2650\n",
      "3480\n",
      "2488\n",
      "6514\n",
      "[Epoch 167/2000] train_loss = 0.55751 train_acc = 0.73724 val_loss = 0.55751 val_acc = 0.74612\n",
      "3163\n",
      "1823\n",
      "3021\n",
      "2326\n",
      "2263\n",
      "3480\n",
      "1377\n",
      "591\n",
      "3312\n",
      "1878\n",
      "2794\n",
      "2339\n",
      "2401\n",
      "2650\n",
      "1819\n",
      "2815\n",
      "1578\n",
      "1767\n",
      "2488\n",
      "1021\n",
      "6514\n",
      "[Epoch 168/2000] train_loss = 0.59263 train_acc = 0.73724 val_loss = 0.59263 val_acc = 0.74611\n",
      "3021\n",
      "1377\n",
      "3480\n",
      "2488\n",
      "2401\n",
      "2263\n",
      "1767\n",
      "1819\n",
      "2326\n",
      "591\n",
      "1021\n",
      "2650\n",
      "2815\n",
      "1578\n",
      "3163\n",
      "1823\n",
      "2339\n",
      "3312\n",
      "1878\n",
      "2794\n",
      "6514\n",
      "[Epoch 169/2000] train_loss = 0.56181 train_acc = 0.73724 val_loss = 0.56181 val_acc = 0.74612\n",
      "3021\n",
      "2263\n",
      "2401\n",
      "1578\n",
      "591\n",
      "1767\n",
      "2488\n",
      "2650\n",
      "1878\n",
      "3312\n",
      "1823\n",
      "3480\n",
      "1819\n",
      "1021\n",
      "1377\n",
      "3163\n",
      "2326\n",
      "2794\n",
      "2815\n",
      "2339\n",
      "6514\n",
      "[Epoch 170/2000] train_loss = 0.56629 train_acc = 0.73724 val_loss = 0.56629 val_acc = 0.74610\n",
      "1823\n",
      "591\n",
      "2650\n",
      "1767\n",
      "2326\n",
      "2794\n",
      "2815\n",
      "3021\n",
      "1021\n",
      "1578\n",
      "1819\n",
      "3163\n",
      "3480\n",
      "3312\n",
      "2488\n",
      "2263\n",
      "1878\n",
      "2401\n",
      "2339\n",
      "1377\n",
      "6514\n",
      "[Epoch 171/2000] train_loss = 0.56166 train_acc = 0.73724 val_loss = 0.56166 val_acc = 0.74611\n",
      "2794\n",
      "2326\n",
      "3312\n",
      "1878\n",
      "1823\n",
      "2263\n",
      "2339\n",
      "1819\n",
      "1377\n",
      "3021\n",
      "2650\n",
      "2815\n",
      "1767\n",
      "3480\n",
      "1021\n",
      "1578\n",
      "591\n",
      "2488\n",
      "3163\n",
      "2401\n",
      "6514\n",
      "[Epoch 172/2000] train_loss = 0.56948 train_acc = 0.73724 val_loss = 0.56948 val_acc = 0.74611\n",
      "2339\n",
      "2815\n",
      "3021\n",
      "1377\n",
      "1578\n",
      "1878\n",
      "2263\n",
      "2488\n",
      "591\n",
      "1819\n",
      "2650\n",
      "2794\n",
      "3312\n",
      "2401\n",
      "3163\n",
      "1823\n",
      "1021\n",
      "2326\n",
      "1767\n",
      "3480\n",
      "6514\n",
      "[Epoch 173/2000] train_loss = 0.56237 train_acc = 0.73724 val_loss = 0.56237 val_acc = 0.74611\n",
      "1823\n",
      "1377\n",
      "2815\n",
      "3480\n",
      "3312\n",
      "3163\n",
      "2794\n",
      "3021\n",
      "1021\n",
      "2326\n",
      "1819\n",
      "2488\n",
      "2650\n",
      "1767\n",
      "1878\n",
      "1578\n",
      "2401\n",
      "2263\n",
      "591\n",
      "2339\n",
      "6514\n",
      "[Epoch 174/2000] train_loss = 0.59126 train_acc = 0.73724 val_loss = 0.59126 val_acc = 0.74611\n",
      "2488\n",
      "3021\n",
      "1377\n",
      "1021\n",
      "1767\n",
      "2263\n",
      "2794\n",
      "1878\n",
      "2339\n",
      "2815\n",
      "3312\n",
      "2326\n",
      "3480\n",
      "3163\n",
      "1823\n",
      "2650\n",
      "591\n",
      "1819\n",
      "2401\n",
      "1578\n",
      "6514\n",
      "[Epoch 175/2000] train_loss = 0.56193 train_acc = 0.73724 val_loss = 0.56193 val_acc = 0.74611\n",
      "1878\n",
      "2815\n",
      "2650\n",
      "3480\n",
      "1819\n",
      "3163\n",
      "2339\n",
      "591\n",
      "3312\n",
      "2401\n",
      "1823\n",
      "2326\n",
      "1767\n",
      "1578\n",
      "3021\n",
      "2263\n",
      "2488\n",
      "2794\n",
      "1021\n",
      "1377\n",
      "6514\n",
      "[Epoch 176/2000] train_loss = 0.57090 train_acc = 0.73724 val_loss = 0.57090 val_acc = 0.74611\n",
      "3312\n",
      "1878\n",
      "1377\n",
      "1823\n",
      "2650\n",
      "1021\n",
      "1578\n",
      "3163\n",
      "2263\n",
      "2815\n",
      "3021\n",
      "591\n",
      "2488\n",
      "1767\n",
      "2401\n",
      "2326\n",
      "2794\n",
      "3480\n",
      "1819\n",
      "2339\n",
      "6514\n",
      "[Epoch 177/2000] train_loss = 0.56052 train_acc = 0.73725 val_loss = 0.56052 val_acc = 0.74613\n",
      "1021\n",
      "3021\n",
      "2263\n",
      "3312\n",
      "1819\n",
      "1878\n",
      "2488\n",
      "3480\n",
      "1578\n",
      "2650\n",
      "2815\n",
      "2326\n",
      "2794\n",
      "3163\n",
      "2401\n",
      "1767\n",
      "2339\n",
      "1377\n",
      "591\n",
      "1823\n",
      "6514\n",
      "[Epoch 178/2000] train_loss = 0.55642 train_acc = 0.73724 val_loss = 0.55642 val_acc = 0.74611\n",
      "3163\n",
      "2401\n",
      "2326\n",
      "3312\n",
      "1767\n",
      "1819\n",
      "2339\n",
      "2794\n",
      "3480\n",
      "3021\n",
      "2263\n",
      "2815\n",
      "1878\n",
      "1021\n",
      "1823\n",
      "2488\n",
      "2650\n",
      "591\n",
      "1377\n",
      "1578\n",
      "6514\n",
      "[Epoch 179/2000] train_loss = 0.55617 train_acc = 0.73725 val_loss = 0.55617 val_acc = 0.74612\n",
      "3480\n",
      "3021\n",
      "2326\n",
      "3163\n",
      "1578\n",
      "1878\n",
      "2650\n",
      "2263\n",
      "591\n",
      "1767\n",
      "2794\n",
      "1819\n",
      "2815\n",
      "2339\n",
      "2401\n",
      "1377\n",
      "1021\n",
      "1823\n",
      "3312\n",
      "2488\n",
      "6514\n",
      "[Epoch 180/2000] train_loss = 0.58614 train_acc = 0.73727 val_loss = 0.58614 val_acc = 0.74613\n",
      "1377\n",
      "1878\n",
      "2401\n",
      "2650\n",
      "3480\n",
      "1823\n",
      "2339\n",
      "3021\n",
      "1578\n",
      "2815\n",
      "1767\n",
      "3312\n",
      "1819\n",
      "2488\n",
      "3163\n",
      "2794\n",
      "591\n",
      "2263\n",
      "1021\n",
      "2326\n",
      "6514\n",
      "[Epoch 181/2000] train_loss = 0.55655 train_acc = 0.73726 val_loss = 0.55655 val_acc = 0.74613\n",
      "2263\n",
      "3021\n",
      "1578\n",
      "591\n",
      "1377\n",
      "3312\n",
      "1819\n",
      "1878\n",
      "1823\n",
      "3163\n",
      "2815\n",
      "2488\n",
      "2401\n",
      "1767\n",
      "3480\n",
      "2794\n",
      "2650\n",
      "2339\n",
      "1021\n",
      "2326\n",
      "6514\n",
      "[Epoch 182/2000] train_loss = 0.56407 train_acc = 0.73725 val_loss = 0.56407 val_acc = 0.74612\n",
      "1021\n",
      "3480\n",
      "2263\n",
      "1578\n",
      "2650\n",
      "3021\n",
      "1377\n",
      "2401\n",
      "1823\n",
      "2326\n",
      "1767\n",
      "1819\n",
      "1878\n",
      "2794\n",
      "3163\n",
      "2339\n",
      "591\n",
      "2488\n",
      "3312\n",
      "2815\n",
      "6514\n",
      "[Epoch 183/2000] train_loss = 0.57166 train_acc = 0.73725 val_loss = 0.57166 val_acc = 0.74612\n",
      "3163\n",
      "2650\n",
      "2326\n",
      "2263\n",
      "1823\n",
      "2401\n",
      "3480\n",
      "1021\n",
      "2794\n",
      "1878\n",
      "1377\n",
      "1578\n",
      "1767\n",
      "2815\n",
      "591\n",
      "2339\n",
      "1819\n",
      "3312\n",
      "3021\n",
      "2488\n",
      "6514\n",
      "[Epoch 184/2000] train_loss = 0.61208 train_acc = 0.73726 val_loss = 0.61208 val_acc = 0.74612\n",
      "2263\n",
      "2326\n",
      "3021\n",
      "3163\n",
      "1021\n",
      "1823\n",
      "1878\n",
      "2488\n",
      "1819\n",
      "1767\n",
      "2794\n",
      "1377\n",
      "591\n",
      "2815\n",
      "2650\n",
      "3480\n",
      "1578\n",
      "2339\n",
      "2401\n",
      "3312\n",
      "6514\n",
      "[Epoch 185/2000] train_loss = 0.56405 train_acc = 0.73726 val_loss = 0.56405 val_acc = 0.74613\n",
      "3021\n",
      "1819\n",
      "2794\n",
      "2650\n",
      "2263\n",
      "2326\n",
      "1767\n",
      "1578\n",
      "1823\n",
      "3163\n",
      "2815\n",
      "2488\n",
      "1878\n",
      "591\n",
      "1021\n",
      "2401\n",
      "3480\n",
      "2339\n",
      "1377\n",
      "3312\n",
      "6514\n",
      "[Epoch 186/2000] train_loss = 0.56364 train_acc = 0.73728 val_loss = 0.56364 val_acc = 0.74614\n",
      "2263\n",
      "1819\n",
      "1767\n",
      "2339\n",
      "3480\n",
      "2326\n",
      "1823\n",
      "1377\n",
      "2401\n",
      "591\n",
      "3021\n",
      "3163\n",
      "2650\n",
      "1578\n",
      "1021\n",
      "2488\n",
      "2794\n",
      "2815\n",
      "3312\n",
      "1878\n",
      "6514\n",
      "[Epoch 187/2000] train_loss = 0.58501 train_acc = 0.73726 val_loss = 0.58501 val_acc = 0.74612\n",
      "2488\n",
      "1767\n",
      "1878\n",
      "3480\n",
      "2815\n",
      "591\n",
      "1377\n",
      "2650\n",
      "2263\n",
      "1021\n",
      "2401\n",
      "1823\n",
      "3312\n",
      "1578\n",
      "2326\n",
      "3163\n",
      "3021\n",
      "2794\n",
      "1819\n",
      "2339\n",
      "6514\n",
      "[Epoch 188/2000] train_loss = 0.56811 train_acc = 0.73725 val_loss = 0.56811 val_acc = 0.74611\n",
      "1819\n",
      "2339\n",
      "3312\n",
      "2794\n",
      "591\n",
      "1021\n",
      "1823\n",
      "2488\n",
      "2650\n",
      "2401\n",
      "3163\n",
      "3021\n",
      "1578\n",
      "3480\n",
      "1767\n",
      "2815\n",
      "1878\n",
      "2326\n",
      "1377\n",
      "2263\n",
      "6514\n",
      "[Epoch 189/2000] train_loss = 0.55904 train_acc = 0.73727 val_loss = 0.55904 val_acc = 0.74612\n",
      "1819\n",
      "2815\n",
      "3312\n",
      "3480\n",
      "1021\n",
      "2401\n",
      "3163\n",
      "1823\n",
      "1377\n",
      "3021\n",
      "2650\n",
      "2263\n",
      "1578\n",
      "2794\n",
      "2326\n",
      "2488\n",
      "1767\n",
      "591\n",
      "2339\n",
      "1878\n",
      "6514\n",
      "[Epoch 190/2000] train_loss = 0.55976 train_acc = 0.73729 val_loss = 0.55976 val_acc = 0.74616\n",
      "1819\n",
      "3163\n",
      "2401\n",
      "2263\n",
      "2650\n",
      "1878\n",
      "2488\n",
      "3021\n",
      "2326\n",
      "1767\n",
      "1021\n",
      "3480\n",
      "1377\n",
      "1578\n",
      "1823\n",
      "3312\n",
      "591\n",
      "2794\n",
      "2815\n",
      "2339\n",
      "6514\n",
      "[Epoch 191/2000] train_loss = 0.58678 train_acc = 0.73729 val_loss = 0.58678 val_acc = 0.74615\n",
      "2339\n",
      "3312\n",
      "2650\n",
      "2326\n",
      "1819\n",
      "3021\n",
      "1021\n",
      "2815\n",
      "3480\n",
      "591\n",
      "2401\n",
      "1578\n",
      "3163\n",
      "1767\n",
      "2488\n",
      "2263\n",
      "1878\n",
      "1823\n",
      "2794\n",
      "1377\n",
      "6514\n",
      "[Epoch 192/2000] train_loss = 0.55939 train_acc = 0.73728 val_loss = 0.55939 val_acc = 0.74615\n",
      "1878\n",
      "2794\n",
      "2326\n",
      "2488\n",
      "591\n",
      "1767\n",
      "1819\n",
      "1021\n",
      "2815\n",
      "2263\n",
      "3480\n",
      "3163\n",
      "1823\n",
      "3312\n",
      "1578\n",
      "2650\n",
      "2339\n",
      "1377\n",
      "3021\n",
      "2401\n",
      "6514\n",
      "[Epoch 193/2000] train_loss = 0.55258 train_acc = 0.73727 val_loss = 0.55258 val_acc = 0.74613\n",
      "2815\n",
      "1021\n",
      "2263\n",
      "2794\n",
      "2488\n",
      "1377\n",
      "3163\n",
      "2326\n",
      "1767\n",
      "1819\n",
      "3021\n",
      "3480\n",
      "1878\n",
      "2339\n",
      "1578\n",
      "3312\n",
      "2401\n",
      "591\n",
      "1823\n",
      "2650\n",
      "6514\n",
      "[Epoch 194/2000] train_loss = 0.56235 train_acc = 0.73727 val_loss = 0.56235 val_acc = 0.74614\n",
      "1878\n",
      "1767\n",
      "2488\n",
      "2263\n",
      "3480\n",
      "2650\n",
      "2794\n",
      "1377\n",
      "591\n",
      "1819\n",
      "1021\n",
      "2326\n",
      "2815\n",
      "2339\n",
      "2401\n",
      "3021\n",
      "3312\n",
      "1823\n",
      "3163\n",
      "1578\n",
      "6514\n",
      "[Epoch 195/2000] train_loss = 0.55195 train_acc = 0.73728 val_loss = 0.55195 val_acc = 0.74615\n",
      "1767\n",
      "2401\n",
      "2263\n",
      "3480\n",
      "3163\n",
      "1819\n",
      "1578\n",
      "2488\n",
      "2339\n",
      "3312\n",
      "2326\n",
      "3021\n",
      "591\n",
      "1823\n",
      "2650\n",
      "1377\n",
      "2815\n",
      "2794\n",
      "1021\n",
      "1878\n",
      "6514\n",
      "[Epoch 196/2000] train_loss = 0.55613 train_acc = 0.73728 val_loss = 0.55613 val_acc = 0.74614\n",
      "2263\n",
      "1819\n",
      "2339\n",
      "591\n",
      "2794\n",
      "3312\n",
      "1767\n",
      "3021\n",
      "1878\n",
      "2815\n",
      "1823\n",
      "1377\n",
      "2401\n",
      "1578\n",
      "1021\n",
      "2488\n",
      "2326\n",
      "3480\n",
      "3163\n",
      "2650\n",
      "6514\n",
      "[Epoch 197/2000] train_loss = 0.58379 train_acc = 0.73730 val_loss = 0.58379 val_acc = 0.74616\n",
      "1578\n",
      "3312\n",
      "2488\n",
      "1377\n",
      "1767\n",
      "1878\n",
      "2339\n",
      "1021\n",
      "2794\n",
      "3163\n",
      "2650\n",
      "2263\n",
      "591\n",
      "3021\n",
      "1819\n",
      "2815\n",
      "3480\n",
      "2326\n",
      "1823\n",
      "2401\n",
      "6514\n",
      "[Epoch 198/2000] train_loss = 0.56485 train_acc = 0.73728 val_loss = 0.56485 val_acc = 0.74616\n",
      "3312\n",
      "2650\n",
      "2326\n",
      "1819\n",
      "2401\n",
      "3480\n",
      "1377\n",
      "2815\n",
      "3021\n",
      "2488\n",
      "1021\n",
      "2263\n",
      "3163\n",
      "1767\n",
      "1878\n",
      "2339\n",
      "2794\n",
      "1578\n",
      "591\n",
      "1823\n",
      "6514\n",
      "[Epoch 199/2000] train_loss = 0.55600 train_acc = 0.73728 val_loss = 0.55600 val_acc = 0.74616\n",
      "3163\n",
      "2263\n",
      "1767\n",
      "1878\n",
      "1819\n",
      "2488\n",
      "2401\n",
      "2815\n",
      "1823\n",
      "2794\n",
      "3312\n",
      "3480\n",
      "1578\n",
      "591\n",
      "2339\n",
      "3021\n",
      "2650\n",
      "2326\n",
      "1021\n",
      "1377\n",
      "6514\n",
      "[Epoch 200/2000] train_loss = 0.60979 train_acc = 0.73730 val_loss = 0.60979 val_acc = 0.74616\n",
      "1377\n",
      "2263\n",
      "1819\n",
      "2650\n",
      "591\n",
      "2401\n",
      "1878\n",
      "1823\n",
      "1767\n",
      "1021\n",
      "3021\n",
      "3312\n",
      "2339\n",
      "2815\n",
      "3163\n",
      "2488\n",
      "3480\n",
      "2326\n",
      "1578\n",
      "2794\n",
      "6514\n",
      "[Epoch 201/2000] train_loss = 0.56096 train_acc = 0.73728 val_loss = 0.56096 val_acc = 0.74616\n",
      "1878\n",
      "1767\n",
      "2488\n",
      "2263\n",
      "2815\n",
      "591\n",
      "1819\n",
      "2326\n",
      "2339\n",
      "2650\n",
      "1823\n",
      "1377\n",
      "3163\n",
      "3480\n",
      "1021\n",
      "3312\n",
      "2401\n",
      "1578\n",
      "2794\n",
      "3021\n",
      "6514\n",
      "[Epoch 202/2000] train_loss = 0.55788 train_acc = 0.73728 val_loss = 0.55788 val_acc = 0.74615\n",
      "3021\n",
      "1767\n",
      "2794\n",
      "2326\n",
      "2263\n",
      "1878\n",
      "2650\n",
      "1578\n",
      "3480\n",
      "2339\n",
      "1021\n",
      "1819\n",
      "1823\n",
      "3312\n",
      "591\n",
      "1377\n",
      "2401\n",
      "2815\n",
      "3163\n",
      "2488\n",
      "6514\n",
      "[Epoch 203/2000] train_loss = 0.56098 train_acc = 0.73729 val_loss = 0.56098 val_acc = 0.74615\n",
      "2794\n",
      "1767\n",
      "2650\n",
      "1578\n",
      "1878\n",
      "3163\n",
      "3021\n",
      "2326\n",
      "2339\n",
      "3312\n",
      "1377\n",
      "1819\n",
      "3480\n",
      "591\n",
      "1021\n",
      "2488\n",
      "1823\n",
      "2401\n",
      "2263\n",
      "2815\n",
      "6514\n",
      "[Epoch 204/2000] train_loss = 0.56009 train_acc = 0.73730 val_loss = 0.56009 val_acc = 0.74616\n",
      "1823\n",
      "3480\n",
      "2794\n",
      "1578\n",
      "2326\n",
      "2650\n",
      "1878\n",
      "2488\n",
      "2401\n",
      "1819\n",
      "3163\n",
      "3312\n",
      "2815\n",
      "1377\n",
      "1767\n",
      "2339\n",
      "1021\n",
      "3021\n",
      "591\n",
      "2263\n",
      "6514\n",
      "[Epoch 205/2000] train_loss = 0.56017 train_acc = 0.73731 val_loss = 0.56017 val_acc = 0.74617\n",
      "591\n",
      "2488\n",
      "1377\n",
      "1819\n",
      "2401\n",
      "1878\n",
      "3021\n",
      "1767\n",
      "1021\n",
      "3163\n",
      "2815\n",
      "3480\n",
      "2650\n",
      "2794\n",
      "2263\n",
      "3312\n",
      "1578\n",
      "1823\n",
      "2326\n",
      "2339\n",
      "6514\n",
      "[Epoch 206/2000] train_loss = 0.58421 train_acc = 0.73731 val_loss = 0.58421 val_acc = 0.74617\n",
      "2794\n",
      "2401\n",
      "1823\n",
      "591\n",
      "2488\n",
      "1578\n",
      "3163\n",
      "2326\n",
      "2263\n",
      "1878\n",
      "3021\n",
      "2339\n",
      "1767\n",
      "3480\n",
      "3312\n",
      "2815\n",
      "1819\n",
      "1021\n",
      "1377\n",
      "2650\n",
      "6514\n",
      "[Epoch 207/2000] train_loss = 0.56879 train_acc = 0.73730 val_loss = 0.56879 val_acc = 0.74617\n",
      "1021\n",
      "2815\n",
      "2488\n",
      "2650\n",
      "1823\n",
      "1578\n",
      "3021\n",
      "2339\n",
      "2326\n",
      "591\n",
      "2401\n",
      "1767\n",
      "3312\n",
      "3163\n",
      "1878\n",
      "1819\n",
      "3480\n",
      "1377\n",
      "2794\n",
      "2263\n",
      "6514\n",
      "[Epoch 208/2000] train_loss = 0.58186 train_acc = 0.73732 val_loss = 0.58186 val_acc = 0.74617\n",
      "3480\n",
      "2401\n",
      "1878\n",
      "2650\n",
      "2815\n",
      "591\n",
      "1377\n",
      "2326\n",
      "3312\n",
      "1021\n",
      "2339\n",
      "1819\n",
      "2263\n",
      "3021\n",
      "2794\n",
      "1767\n",
      "1578\n",
      "3163\n",
      "1823\n",
      "2488\n",
      "6514\n",
      "[Epoch 209/2000] train_loss = 0.58388 train_acc = 0.73730 val_loss = 0.58388 val_acc = 0.74616\n",
      "1878\n",
      "1819\n",
      "1377\n",
      "2326\n",
      "2794\n",
      "1021\n",
      "2263\n",
      "3021\n",
      "1767\n",
      "1823\n",
      "2488\n",
      "3480\n",
      "1578\n",
      "2815\n",
      "2650\n",
      "3163\n",
      "2401\n",
      "3312\n",
      "591\n",
      "2339\n",
      "6514\n",
      "[Epoch 210/2000] train_loss = 0.58146 train_acc = 0.73731 val_loss = 0.58146 val_acc = 0.74618\n",
      "1377\n",
      "1021\n",
      "3312\n",
      "2339\n",
      "2794\n",
      "3163\n",
      "3021\n",
      "3480\n",
      "591\n",
      "2326\n",
      "2815\n",
      "1767\n",
      "1819\n",
      "2401\n",
      "2488\n",
      "1823\n",
      "1578\n",
      "2650\n",
      "2263\n",
      "1878\n",
      "6514\n",
      "[Epoch 211/2000] train_loss = 0.55317 train_acc = 0.73730 val_loss = 0.55317 val_acc = 0.74615\n",
      "1819\n",
      "2488\n",
      "591\n",
      "2401\n",
      "3480\n",
      "3021\n",
      "2339\n",
      "2815\n",
      "1021\n",
      "2263\n",
      "3312\n",
      "1767\n",
      "2650\n",
      "2326\n",
      "1823\n",
      "3163\n",
      "2794\n",
      "1878\n",
      "1578\n",
      "1377\n",
      "6514\n",
      "[Epoch 212/2000] train_loss = 0.55904 train_acc = 0.73733 val_loss = 0.55904 val_acc = 0.74618\n",
      "3021\n",
      "3480\n",
      "1021\n",
      "2815\n",
      "1823\n",
      "2650\n",
      "2401\n",
      "2263\n",
      "1767\n",
      "1819\n",
      "591\n",
      "3312\n",
      "1878\n",
      "1377\n",
      "2794\n",
      "3163\n",
      "2326\n",
      "2488\n",
      "1578\n",
      "2339\n",
      "6514\n",
      "[Epoch 213/2000] train_loss = 0.56425 train_acc = 0.73732 val_loss = 0.56425 val_acc = 0.74618\n",
      "1767\n",
      "3163\n",
      "1578\n",
      "2794\n",
      "2263\n",
      "2650\n",
      "3480\n",
      "3021\n",
      "3312\n",
      "2488\n",
      "2401\n",
      "2326\n",
      "1377\n",
      "2339\n",
      "1021\n",
      "591\n",
      "1878\n",
      "1823\n",
      "1819\n",
      "2815\n",
      "6514\n",
      "[Epoch 214/2000] train_loss = 0.60615 train_acc = 0.73733 val_loss = 0.60615 val_acc = 0.74618\n",
      "2401\n",
      "1819\n",
      "1021\n",
      "2650\n",
      "2794\n",
      "1377\n",
      "1878\n",
      "1578\n",
      "2815\n",
      "2263\n",
      "3480\n",
      "591\n",
      "2339\n",
      "3021\n",
      "3312\n",
      "1823\n",
      "3163\n",
      "1767\n",
      "2326\n",
      "2488\n",
      "6514\n",
      "[Epoch 215/2000] train_loss = 0.56208 train_acc = 0.73733 val_loss = 0.56208 val_acc = 0.74618\n",
      "1878\n",
      "2650\n",
      "2339\n",
      "591\n",
      "2488\n",
      "1823\n",
      "1377\n",
      "1021\n",
      "3163\n",
      "2326\n",
      "1578\n",
      "1819\n",
      "1767\n",
      "2401\n",
      "3021\n",
      "3312\n",
      "2263\n",
      "2815\n",
      "2794\n",
      "3480\n",
      "6514\n",
      "[Epoch 216/2000] train_loss = 0.55445 train_acc = 0.73733 val_loss = 0.55445 val_acc = 0.74618\n",
      "2794\n",
      "591\n",
      "1823\n",
      "1819\n",
      "3163\n",
      "2401\n",
      "3312\n",
      "1578\n",
      "1767\n",
      "3021\n",
      "2815\n",
      "2488\n",
      "2339\n",
      "1021\n",
      "1878\n",
      "1377\n",
      "2650\n",
      "2326\n",
      "3480\n",
      "2263\n",
      "6514\n",
      "[Epoch 217/2000] train_loss = 0.56743 train_acc = 0.73735 val_loss = 0.56743 val_acc = 0.74619\n",
      "2263\n",
      "1767\n",
      "1878\n",
      "2794\n",
      "2815\n",
      "2401\n",
      "3480\n",
      "2650\n",
      "1377\n",
      "2488\n",
      "3021\n",
      "591\n",
      "2326\n",
      "1819\n",
      "3163\n",
      "3312\n",
      "2339\n",
      "1021\n",
      "1823\n",
      "1578\n",
      "6514\n",
      "[Epoch 218/2000] train_loss = 0.56640 train_acc = 0.73736 val_loss = 0.56640 val_acc = 0.74619\n",
      "2794\n",
      "3021\n",
      "1578\n",
      "3312\n",
      "1767\n",
      "3163\n",
      "2815\n",
      "2488\n",
      "1377\n",
      "2650\n",
      "1878\n",
      "2326\n",
      "1021\n",
      "591\n",
      "2263\n",
      "2401\n",
      "3480\n",
      "1819\n",
      "2339\n",
      "1823\n",
      "6514\n",
      "[Epoch 219/2000] train_loss = 0.55141 train_acc = 0.73735 val_loss = 0.55141 val_acc = 0.74618\n",
      "1819\n",
      "2794\n",
      "2488\n",
      "2263\n",
      "2401\n",
      "1767\n",
      "1578\n",
      "3021\n",
      "1823\n",
      "2815\n",
      "1021\n",
      "2326\n",
      "591\n",
      "3480\n",
      "2650\n",
      "1878\n",
      "1377\n",
      "2339\n",
      "3163\n",
      "3312\n",
      "6514\n",
      "[Epoch 220/2000] train_loss = 0.55288 train_acc = 0.73735 val_loss = 0.55288 val_acc = 0.74618\n",
      "1823\n",
      "2263\n",
      "3021\n",
      "1578\n",
      "1021\n",
      "1878\n",
      "3163\n",
      "1819\n",
      "591\n",
      "2488\n",
      "2326\n",
      "2815\n",
      "2401\n",
      "2650\n",
      "3480\n",
      "2794\n",
      "1767\n",
      "1377\n",
      "3312\n",
      "2339\n",
      "6514\n",
      "[Epoch 221/2000] train_loss = 0.58017 train_acc = 0.73736 val_loss = 0.58017 val_acc = 0.74621\n",
      "1021\n",
      "2339\n",
      "1578\n",
      "1767\n",
      "591\n",
      "1377\n",
      "2401\n",
      "2263\n",
      "2815\n",
      "2794\n",
      "2650\n",
      "1823\n",
      "1819\n",
      "3163\n",
      "2488\n",
      "2326\n",
      "3480\n",
      "3312\n",
      "3021\n",
      "1878\n",
      "6514\n",
      "[Epoch 222/2000] train_loss = 0.54664 train_acc = 0.73735 val_loss = 0.54664 val_acc = 0.74618\n",
      "3480\n",
      "1819\n",
      "591\n",
      "2263\n",
      "3021\n",
      "2794\n",
      "2339\n",
      "1767\n",
      "1878\n",
      "3312\n",
      "2401\n",
      "2650\n",
      "1823\n",
      "1578\n",
      "1021\n",
      "2326\n",
      "2815\n",
      "3163\n",
      "2488\n",
      "1377\n",
      "6514\n",
      "[Epoch 223/2000] train_loss = 0.56033 train_acc = 0.73735 val_loss = 0.56033 val_acc = 0.74619\n",
      "2401\n",
      "1878\n",
      "1021\n",
      "2326\n",
      "1767\n",
      "3021\n",
      "3480\n",
      "3163\n",
      "2650\n",
      "2794\n",
      "2488\n",
      "2815\n",
      "2263\n",
      "2339\n",
      "1578\n",
      "1819\n",
      "1823\n",
      "1377\n",
      "591\n",
      "3312\n",
      "6514\n",
      "[Epoch 224/2000] train_loss = 0.55936 train_acc = 0.73736 val_loss = 0.55936 val_acc = 0.74620\n",
      "3163\n",
      "2488\n",
      "1823\n",
      "1578\n",
      "2794\n",
      "2339\n",
      "3312\n",
      "1021\n",
      "1819\n",
      "2401\n",
      "1767\n",
      "2326\n",
      "2263\n",
      "1377\n",
      "2650\n",
      "1878\n",
      "3480\n",
      "3021\n",
      "591\n",
      "2815\n",
      "6514\n",
      "[Epoch 225/2000] train_loss = 0.56019 train_acc = 0.73736 val_loss = 0.56019 val_acc = 0.74619\n",
      "2815\n",
      "2339\n",
      "2488\n",
      "1021\n",
      "3163\n",
      "2794\n",
      "2326\n",
      "1578\n",
      "2650\n",
      "2263\n",
      "1819\n",
      "3480\n",
      "591\n",
      "3312\n",
      "1878\n",
      "1823\n",
      "3021\n",
      "1767\n",
      "2401\n",
      "1377\n",
      "6514\n",
      "[Epoch 226/2000] train_loss = 0.55098 train_acc = 0.73736 val_loss = 0.55098 val_acc = 0.74620\n",
      "1767\n",
      "2326\n",
      "1878\n",
      "3021\n",
      "2815\n",
      "2263\n",
      "1377\n",
      "591\n",
      "1823\n",
      "3312\n",
      "1578\n",
      "1021\n",
      "3163\n",
      "2794\n",
      "2401\n",
      "2488\n",
      "2339\n",
      "3480\n",
      "2650\n",
      "1819\n",
      "6514\n",
      "[Epoch 227/2000] train_loss = 0.55004 train_acc = 0.73736 val_loss = 0.55004 val_acc = 0.74619\n",
      "2263\n",
      "2326\n",
      "2794\n",
      "1377\n",
      "1578\n",
      "1878\n",
      "2401\n",
      "2488\n",
      "1021\n",
      "2815\n",
      "591\n",
      "3021\n",
      "1767\n",
      "3163\n",
      "1819\n",
      "2339\n",
      "1823\n",
      "3312\n",
      "3480\n",
      "2650\n",
      "6514\n",
      "[Epoch 228/2000] train_loss = 0.56448 train_acc = 0.73736 val_loss = 0.56448 val_acc = 0.74620\n",
      "3021\n",
      "1377\n",
      "1823\n",
      "2650\n",
      "3480\n",
      "2488\n",
      "2326\n",
      "1578\n",
      "591\n",
      "1878\n",
      "1767\n",
      "2339\n",
      "2401\n",
      "2263\n",
      "3163\n",
      "2815\n",
      "1819\n",
      "1021\n",
      "3312\n",
      "2794\n",
      "6514\n",
      "[Epoch 229/2000] train_loss = 0.55837 train_acc = 0.73736 val_loss = 0.55837 val_acc = 0.74618\n",
      "591\n",
      "2263\n",
      "1767\n",
      "2488\n",
      "2650\n",
      "3163\n",
      "2794\n",
      "2815\n",
      "2339\n",
      "1377\n",
      "2401\n",
      "1878\n",
      "1819\n",
      "1578\n",
      "3312\n",
      "2326\n",
      "1823\n",
      "3480\n",
      "3021\n",
      "1021\n",
      "6514\n",
      "[Epoch 230/2000] train_loss = 0.55977 train_acc = 0.73736 val_loss = 0.55977 val_acc = 0.74622\n",
      "3312\n",
      "3021\n",
      "1823\n",
      "2401\n",
      "1377\n",
      "2339\n",
      "1819\n",
      "2263\n",
      "3480\n",
      "2326\n",
      "3163\n",
      "1878\n",
      "1578\n",
      "2815\n",
      "2650\n",
      "2794\n",
      "591\n",
      "2488\n",
      "1767\n",
      "1021\n",
      "6514\n",
      "[Epoch 231/2000] train_loss = 0.57942 train_acc = 0.73736 val_loss = 0.57942 val_acc = 0.74623\n",
      "1377\n",
      "2650\n",
      "1823\n",
      "1021\n",
      "3021\n",
      "591\n",
      "1878\n",
      "2488\n",
      "2815\n",
      "2339\n",
      "1767\n",
      "1578\n",
      "3312\n",
      "2794\n",
      "2263\n",
      "2401\n",
      "2326\n",
      "1819\n",
      "3163\n",
      "3480\n",
      "6514\n",
      "[Epoch 232/2000] train_loss = 0.55016 train_acc = 0.73737 val_loss = 0.55016 val_acc = 0.74623\n",
      "1021\n",
      "1819\n",
      "3312\n",
      "2401\n",
      "2815\n",
      "2650\n",
      "1823\n",
      "1878\n",
      "1767\n",
      "2488\n",
      "2794\n",
      "1578\n",
      "3021\n",
      "2339\n",
      "1377\n",
      "3480\n",
      "2326\n",
      "2263\n",
      "591\n",
      "3163\n",
      "6514\n",
      "[Epoch 233/2000] train_loss = 0.54984 train_acc = 0.73736 val_loss = 0.54984 val_acc = 0.74626\n",
      "2263\n",
      "1021\n",
      "1878\n",
      "3480\n",
      "1578\n",
      "591\n",
      "1767\n",
      "3163\n",
      "2650\n",
      "3021\n",
      "1819\n",
      "1377\n",
      "2339\n",
      "2488\n",
      "2794\n",
      "2815\n",
      "1823\n",
      "2326\n",
      "3312\n",
      "2401\n",
      "6514\n",
      "[Epoch 234/2000] train_loss = 0.54935 train_acc = 0.73736 val_loss = 0.54935 val_acc = 0.74626\n",
      "2815\n",
      "2326\n",
      "1021\n",
      "1878\n",
      "591\n",
      "2263\n",
      "3163\n",
      "1823\n",
      "1377\n",
      "3480\n",
      "2794\n",
      "1819\n",
      "3021\n",
      "1767\n",
      "3312\n",
      "2401\n",
      "2650\n",
      "1578\n",
      "2339\n",
      "2488\n",
      "6514\n",
      "[Epoch 235/2000] train_loss = 0.54418 train_acc = 0.73737 val_loss = 0.54418 val_acc = 0.74625\n",
      "3312\n",
      "1823\n",
      "1021\n",
      "2339\n",
      "2794\n",
      "2401\n",
      "1767\n",
      "2815\n",
      "3480\n",
      "591\n",
      "3163\n",
      "1377\n",
      "1578\n",
      "2650\n",
      "1819\n",
      "1878\n",
      "3021\n",
      "2488\n",
      "2263\n",
      "2326\n",
      "6514\n",
      "[Epoch 236/2000] train_loss = 0.55096 train_acc = 0.73736 val_loss = 0.55096 val_acc = 0.74624\n",
      "2794\n",
      "1578\n",
      "1878\n",
      "2339\n",
      "2401\n",
      "2815\n",
      "3312\n",
      "1767\n",
      "2650\n",
      "3480\n",
      "1823\n",
      "1819\n",
      "3021\n",
      "1377\n",
      "2263\n",
      "1021\n",
      "591\n",
      "2326\n",
      "3163\n",
      "2488\n",
      "6514\n",
      "[Epoch 237/2000] train_loss = 0.57881 train_acc = 0.73737 val_loss = 0.57881 val_acc = 0.74628\n",
      "1878\n",
      "591\n",
      "2815\n",
      "3312\n",
      "2263\n",
      "1578\n",
      "2794\n",
      "1767\n",
      "3480\n",
      "1823\n",
      "2401\n",
      "2326\n",
      "1819\n",
      "3163\n",
      "1377\n",
      "2650\n",
      "3021\n",
      "1021\n",
      "2488\n",
      "2339\n",
      "6514\n",
      "[Epoch 238/2000] train_loss = 0.55393 train_acc = 0.73736 val_loss = 0.55393 val_acc = 0.74627\n",
      "2339\n",
      "2263\n",
      "3021\n",
      "2326\n",
      "1819\n",
      "2650\n",
      "1021\n",
      "591\n",
      "3312\n",
      "2794\n",
      "1823\n",
      "1767\n",
      "3480\n",
      "1377\n",
      "1578\n",
      "2488\n",
      "1878\n",
      "2401\n",
      "2815\n",
      "3163\n",
      "6514\n",
      "[Epoch 239/2000] train_loss = 0.57718 train_acc = 0.73736 val_loss = 0.57718 val_acc = 0.74628\n",
      "2815\n",
      "1878\n",
      "3163\n",
      "2326\n",
      "1767\n",
      "3021\n",
      "1021\n",
      "2401\n",
      "2263\n",
      "2339\n",
      "1377\n",
      "3480\n",
      "2650\n",
      "591\n",
      "1819\n",
      "1578\n",
      "3312\n",
      "2488\n",
      "1823\n",
      "2794\n",
      "6514\n",
      "[Epoch 240/2000] train_loss = 0.55615 train_acc = 0.73737 val_loss = 0.55615 val_acc = 0.74627\n",
      "1767\n",
      "1878\n",
      "2401\n",
      "1819\n",
      "2326\n",
      "2339\n",
      "2263\n",
      "3480\n",
      "1823\n",
      "1578\n",
      "3163\n",
      "2650\n",
      "3021\n",
      "1377\n",
      "2794\n",
      "591\n",
      "2815\n",
      "1021\n",
      "3312\n",
      "2488\n",
      "6514\n",
      "[Epoch 241/2000] train_loss = 0.55366 train_acc = 0.73736 val_loss = 0.55366 val_acc = 0.74630\n",
      "1767\n",
      "3163\n",
      "1021\n",
      "3312\n",
      "2263\n",
      "2794\n",
      "1578\n",
      "2815\n",
      "2339\n",
      "1823\n",
      "3021\n",
      "1878\n",
      "2401\n",
      "3480\n",
      "2650\n",
      "2488\n",
      "1819\n",
      "1377\n",
      "591\n",
      "2326\n",
      "6514\n",
      "[Epoch 242/2000] train_loss = 0.54964 train_acc = 0.73738 val_loss = 0.54964 val_acc = 0.74633\n",
      "1021\n",
      "1767\n",
      "591\n",
      "2339\n",
      "2401\n",
      "2326\n",
      "3021\n",
      "3480\n",
      "2488\n",
      "1377\n",
      "2650\n",
      "1578\n",
      "3312\n",
      "3163\n",
      "2794\n",
      "2815\n",
      "1878\n",
      "1823\n",
      "2263\n",
      "1819\n",
      "6514\n",
      "[Epoch 243/2000] train_loss = 0.59994 train_acc = 0.73741 val_loss = 0.59994 val_acc = 0.74637\n",
      "2794\n",
      "2401\n",
      "1823\n",
      "3312\n",
      "1578\n",
      "2326\n",
      "1819\n",
      "2650\n",
      "2488\n",
      "1767\n",
      "591\n",
      "1878\n",
      "3480\n",
      "2339\n",
      "3021\n",
      "1021\n",
      "2815\n",
      "1377\n",
      "2263\n",
      "3163\n",
      "6514\n",
      "[Epoch 244/2000] train_loss = 0.54959 train_acc = 0.73739 val_loss = 0.54959 val_acc = 0.74635\n",
      "1578\n",
      "3163\n",
      "1823\n",
      "1878\n",
      "1767\n",
      "2326\n",
      "2794\n",
      "2263\n",
      "3021\n",
      "1377\n",
      "2488\n",
      "1819\n",
      "2815\n",
      "3480\n",
      "1021\n",
      "3312\n",
      "2339\n",
      "591\n",
      "2401\n",
      "2650\n",
      "6514\n",
      "[Epoch 245/2000] train_loss = 0.54353 train_acc = 0.73740 val_loss = 0.54353 val_acc = 0.74635\n",
      "1021\n",
      "2339\n",
      "2488\n",
      "1878\n",
      "3312\n",
      "3021\n",
      "2815\n",
      "2263\n",
      "2326\n",
      "591\n",
      "2401\n",
      "1578\n",
      "1767\n",
      "1823\n",
      "3480\n",
      "1819\n",
      "2650\n",
      "1377\n",
      "3163\n",
      "2794\n",
      "6514\n",
      "[Epoch 246/2000] train_loss = 0.57684 train_acc = 0.73741 val_loss = 0.57684 val_acc = 0.74639\n",
      "2326\n",
      "1823\n",
      "1878\n",
      "1767\n",
      "2815\n",
      "1377\n",
      "2339\n",
      "3163\n",
      "1021\n",
      "2263\n",
      "2488\n",
      "591\n",
      "2794\n",
      "1819\n",
      "2401\n",
      "3312\n",
      "1578\n",
      "2650\n",
      "3021\n",
      "3480\n",
      "6514\n",
      "[Epoch 247/2000] train_loss = 0.55617 train_acc = 0.73743 val_loss = 0.55617 val_acc = 0.74643\n",
      "1767\n",
      "3480\n",
      "2326\n",
      "2263\n",
      "3312\n",
      "1377\n",
      "591\n",
      "2794\n",
      "2650\n",
      "1819\n",
      "2815\n",
      "1878\n",
      "3163\n",
      "1578\n",
      "1823\n",
      "2401\n",
      "3021\n",
      "2488\n",
      "2339\n",
      "1021\n",
      "6514\n",
      "[Epoch 248/2000] train_loss = 0.56230 train_acc = 0.73746 val_loss = 0.56230 val_acc = 0.74644\n",
      "2401\n",
      "1819\n",
      "2339\n",
      "1377\n",
      "591\n",
      "2815\n",
      "2263\n",
      "1878\n",
      "3021\n",
      "1767\n",
      "1823\n",
      "2794\n",
      "3163\n",
      "2326\n",
      "3480\n",
      "3312\n",
      "2650\n",
      "1021\n",
      "1578\n",
      "2488\n",
      "6514\n",
      "[Epoch 249/2000] train_loss = 0.55601 train_acc = 0.73750 val_loss = 0.55601 val_acc = 0.74650\n",
      "3312\n",
      "591\n",
      "1878\n",
      "3480\n",
      "1823\n",
      "2650\n",
      "2339\n",
      "1377\n",
      "1767\n",
      "1578\n",
      "1021\n",
      "3021\n",
      "3163\n",
      "2488\n",
      "1819\n",
      "2815\n",
      "2401\n",
      "2326\n",
      "2794\n",
      "2263\n",
      "6514\n",
      "[Epoch 250/2000] train_loss = 0.57673 train_acc = 0.73755 val_loss = 0.57673 val_acc = 0.74659\n",
      "591\n",
      "2815\n",
      "1878\n",
      "1377\n",
      "2794\n",
      "2263\n",
      "2339\n",
      "1819\n",
      "1021\n",
      "2650\n",
      "1767\n",
      "3163\n",
      "2488\n",
      "3312\n",
      "1823\n",
      "2326\n",
      "1578\n",
      "3480\n",
      "2401\n",
      "3021\n",
      "6514\n",
      "[Epoch 251/2000] train_loss = 0.56180 train_acc = 0.73756 val_loss = 0.56180 val_acc = 0.74660\n",
      "2794\n",
      "3163\n",
      "2815\n",
      "2488\n",
      "1819\n",
      "2401\n",
      "1823\n",
      "3021\n",
      "1021\n",
      "3480\n",
      "2339\n",
      "1878\n",
      "591\n",
      "1767\n",
      "3312\n",
      "1377\n",
      "2650\n",
      "2263\n",
      "2326\n",
      "1578\n",
      "6514\n",
      "[Epoch 252/2000] train_loss = 0.54838 train_acc = 0.73758 val_loss = 0.54838 val_acc = 0.74661\n",
      "3021\n",
      "2488\n",
      "2815\n",
      "2794\n",
      "2650\n",
      "2339\n",
      "1021\n",
      "3480\n",
      "2326\n",
      "1377\n",
      "1823\n",
      "1878\n",
      "2401\n",
      "1819\n",
      "3163\n",
      "1767\n",
      "591\n",
      "2263\n",
      "3312\n",
      "1578\n",
      "6514\n",
      "[Epoch 253/2000] train_loss = 0.57553 train_acc = 0.73760 val_loss = 0.57553 val_acc = 0.74665\n",
      "3480\n",
      "2488\n",
      "1819\n",
      "2263\n",
      "2326\n",
      "2650\n",
      "591\n",
      "2339\n",
      "1878\n",
      "1021\n",
      "2794\n",
      "3163\n",
      "1823\n",
      "1578\n",
      "2401\n",
      "3021\n",
      "3312\n",
      "1377\n",
      "2815\n",
      "1767\n",
      "6514\n",
      "[Epoch 254/2000] train_loss = 0.54830 train_acc = 0.73760 val_loss = 0.54830 val_acc = 0.74666\n",
      "1823\n",
      "1819\n",
      "3312\n",
      "1578\n",
      "3163\n",
      "2488\n",
      "2815\n",
      "2339\n",
      "2401\n",
      "2650\n",
      "1021\n",
      "1767\n",
      "2263\n",
      "3021\n",
      "591\n",
      "3480\n",
      "1878\n",
      "2794\n",
      "2326\n",
      "1377\n",
      "6514\n",
      "[Epoch 255/2000] train_loss = 0.55497 train_acc = 0.73764 val_loss = 0.55497 val_acc = 0.74667\n",
      "1377\n",
      "1767\n",
      "1021\n",
      "2794\n",
      "2488\n",
      "2263\n",
      "2650\n",
      "1819\n",
      "3312\n",
      "2339\n",
      "3021\n",
      "3480\n",
      "3163\n",
      "1823\n",
      "2326\n",
      "1878\n",
      "2815\n",
      "591\n",
      "1578\n",
      "2401\n",
      "6514\n",
      "[Epoch 256/2000] train_loss = 0.54710 train_acc = 0.73766 val_loss = 0.54710 val_acc = 0.74667\n",
      "2815\n",
      "3021\n",
      "2794\n",
      "591\n",
      "2488\n",
      "2263\n",
      "1377\n",
      "1767\n",
      "1878\n",
      "1021\n",
      "2326\n",
      "3480\n",
      "1823\n",
      "2650\n",
      "2339\n",
      "2401\n",
      "3163\n",
      "1819\n",
      "3312\n",
      "1578\n",
      "6514\n",
      "[Epoch 257/2000] train_loss = 0.55092 train_acc = 0.73767 val_loss = 0.55092 val_acc = 0.74669\n",
      "3480\n",
      "3163\n",
      "2650\n",
      "2339\n",
      "1878\n",
      "1578\n",
      "2263\n",
      "1823\n",
      "2401\n",
      "2815\n",
      "1021\n",
      "1377\n",
      "2794\n",
      "3312\n",
      "2326\n",
      "1819\n",
      "591\n",
      "2488\n",
      "1767\n",
      "3021\n",
      "6514\n",
      "[Epoch 258/2000] train_loss = 0.56013 train_acc = 0.73770 val_loss = 0.56013 val_acc = 0.74673\n",
      "2488\n",
      "2401\n",
      "2326\n",
      "3480\n",
      "1377\n",
      "1578\n",
      "1819\n",
      "2815\n",
      "1823\n",
      "591\n",
      "1878\n",
      "3163\n",
      "2263\n",
      "1021\n",
      "3021\n",
      "1767\n",
      "2339\n",
      "2794\n",
      "2650\n",
      "3312\n",
      "6514\n",
      "[Epoch 259/2000] train_loss = 0.59882 train_acc = 0.73773 val_loss = 0.59882 val_acc = 0.74676\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37025/1499540659.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/wangyy/anaconda3/envs/pyg/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_37025/3583812199.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, dataX, dataY)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mconv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;31m#x = global_mean_pool(x, batch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/wangyy/anaconda3/envs/pyg/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/wangyy/anaconda3/envs/pyg/lib/python3.7/site-packages/torch_geometric/nn/conv/gcn_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    176\u001b[0m                     edge_index, edge_weight = gcn_norm(  # yapf: disable\n\u001b[1;32m    177\u001b[0m                         \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                         self.improved, self.add_self_loops, self.flow, x.dtype)\n\u001b[0m\u001b[1;32m    179\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcached\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_edge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/wangyy/anaconda3/envs/pyg/lib/python3.7/site-packages/torch_geometric/nn/conv/gcn_conv.py\u001b[0m in \u001b[0;36mgcn_norm\u001b[0;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_self_loops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             edge_index, tmp_edge_weight = add_remaining_self_loops(\n\u001b[0;32m---> 62\u001b[0;31m                 edge_index, edge_weight, fill_value, num_nodes)\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mtmp_edge_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0medge_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_edge_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/wangyy/anaconda3/envs/pyg/lib/python3.7/site-packages/torch_geometric/utils/loop.py\u001b[0m in \u001b[0;36madd_remaining_self_loops\u001b[0;34m(edge_index, edge_attr, fill_value, num_nodes)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0minv_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mloop_attr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minv_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minv_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0medge_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_attr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "learning_rate = 1e-5\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=5e-4)\n",
    "Loss = torch.nn.BCELoss()\n",
    "epochs = 2000\n",
    "start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x, data.edge_index)\n",
    "        loss = Loss(output, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    train_loss, train_acc = cal_loss_and_acc(train_loader)\n",
    "    val_loss, val_acc = cal_loss_and_acc(val_loader)\n",
    "    model.train()\n",
    "    if (epoch+1) % 1 == 0:\n",
    "        print('[Epoch {}/{}] train_loss = {:.5f} train_acc = {:.5f} val_loss = {:.5f} val_acc = {:.5f}'\n",
    "              .format(epoch + 1, epochs,  train_loss, train_acc, val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.array([[0.1,0,0.5],[0.1,0,0.1],[0.6,0,0.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图有2708个节点，每个点有1433个属性（词汇是否在图上出现过），5429条边"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[3312, 3703], edge_index=[2, 9430], y=[3312, 1])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "transform = RandomLinkSplit(num_val=0.1, num_test=0.1)\n",
    "train_data, val_data, test_data = transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[3312, 3703], edge_index=[2, 7544], y=[3312, 1], edge_label=[15088], edge_label_index=[2, 15088]),\n",
       " Data(x=[3312, 3703], edge_index=[2, 7544], y=[3312, 1], edge_label=[1886], edge_label_index=[2, 1886]),\n",
       " Data(x=[3312, 3703], edge_index=[2, 8487], y=[3312, 1], edge_label=[1886], edge_label_index=[2, 1886]))"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.,  ..., 0., 0., 0.], device='cuda:0')"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.edge_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 四、测试结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mActivating extension 'ms-python.python' failed: TelemetrySender.sendEventData must be a function. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mActivating extension 'ms-python.python' failed: TelemetrySender.sendEventData must be a function. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取最佳模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mActivating extension 'ms-python.python' failed: TelemetrySender.sendEventData must be a function. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "选择验证集上表现最好的模型参数在测试集上测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mActivating extension 'ms-python.python' failed: TelemetrySender.sendEventData must be a function. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model, test_iterator, Loss)\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACC为0.93119"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 五、和RNN模型的比较"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在同为BCELoss的情况下，两者在测试集上的表现为："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model | BCELoss | ACC     |\n",
    "| ----- | ------- | ------- |\n",
    "| RNN   | 0.284   | 89.143% |\n",
    "| BERT  | 0.181   | 93.119% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从模型表现和性能上来说，显然BERT要更优。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当然BERT的参数更多，bert-base-uncased有104w参数，bert-large-uncased有335w参数，所以无论是消耗的显存、以及训练单轮所需要的时间，BERT模型都需要更多。  \n",
    "训练时，bert-base-uncased需要37GB显存和5min单轮训练时间(BATCH_SIZE=32),bert-large-uncased需要29GB显存和36min单轮训练时间(BATCH_SIZE=8)，而RNN模型在BATCH_SIZE=256时也仅需要11GB内存和约40s单轮训练时间。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "e01828c828498a079c167a9a4ddbb31467509f2bad30141868eec41871247a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
